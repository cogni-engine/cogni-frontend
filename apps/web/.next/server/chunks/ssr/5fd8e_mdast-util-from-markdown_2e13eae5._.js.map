{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/unist-util-stringify-position/lib/index.js"],"sourcesContent":["/**\n * @typedef {import('unist').Node} Node\n * @typedef {import('unist').Point} Point\n * @typedef {import('unist').Position} Position\n */\n\n/**\n * @typedef NodeLike\n * @property {string} type\n * @property {PositionLike | null | undefined} [position]\n *\n * @typedef PointLike\n * @property {number | null | undefined} [line]\n * @property {number | null | undefined} [column]\n * @property {number | null | undefined} [offset]\n *\n * @typedef PositionLike\n * @property {PointLike | null | undefined} [start]\n * @property {PointLike | null | undefined} [end]\n */\n\n/**\n * Serialize the positional info of a point, position (start and end points),\n * or node.\n *\n * @param {Node | NodeLike | Point | PointLike | Position | PositionLike | null | undefined} [value]\n *   Node, position, or point.\n * @returns {string}\n *   Pretty printed positional info of a node (`string`).\n *\n *   In the format of a range `ls:cs-le:ce` (when given `node` or `position`)\n *   or a point `l:c` (when given `point`), where `l` stands for line, `c` for\n *   column, `s` for `start`, and `e` for end.\n *   An empty string (`''`) is returned if the given value is neither `node`,\n *   `position`, nor `point`.\n */\nexport function stringifyPosition(value) {\n  // Nothing.\n  if (!value || typeof value !== 'object') {\n    return ''\n  }\n\n  // Node.\n  if ('position' in value || 'type' in value) {\n    return position(value.position)\n  }\n\n  // Position.\n  if ('start' in value || 'end' in value) {\n    return position(value)\n  }\n\n  // Point.\n  if ('line' in value || 'column' in value) {\n    return point(value)\n  }\n\n  // ?\n  return ''\n}\n\n/**\n * @param {Point | PointLike | null | undefined} point\n * @returns {string}\n */\nfunction point(point) {\n  return index(point && point.line) + ':' + index(point && point.column)\n}\n\n/**\n * @param {Position | PositionLike | null | undefined} pos\n * @returns {string}\n */\nfunction position(pos) {\n  return point(pos && pos.start) + '-' + point(pos && pos.end)\n}\n\n/**\n * @param {number | null | undefined} value\n * @returns {number}\n */\nfunction index(value) {\n  return value && typeof value === 'number' ? value : 1\n}\n"],"names":[],"mappings":"AAAA;;;;CAIC,GAED;;;;;;;;;;;;;CAaC,GAED;;;;;;;;;;;;;;CAcC;;;;AACM,SAAS,kBAAkB,KAAK;IACrC,WAAW;IACX,IAAI,CAAC,SAAS,OAAO,UAAU,UAAU;QACvC,OAAO;IACT;IAEA,QAAQ;IACR,IAAI,cAAc,SAAS,UAAU,OAAO;QAC1C,OAAO,SAAS,MAAM,QAAQ;IAChC;IAEA,YAAY;IACZ,IAAI,WAAW,SAAS,SAAS,OAAO;QACtC,OAAO,SAAS;IAClB;IAEA,SAAS;IACT,IAAI,UAAU,SAAS,YAAY,OAAO;QACxC,OAAO,MAAM;IACf;IAEA,IAAI;IACJ,OAAO;AACT;AAEA;;;CAGC,GACD,SAAS,MAAM,KAAK;IAClB,OAAO,MAAM,SAAS,MAAM,IAAI,IAAI,MAAM,MAAM,SAAS,MAAM,MAAM;AACvE;AAEA;;;CAGC,GACD,SAAS,SAAS,GAAG;IACnB,OAAO,MAAM,OAAO,IAAI,KAAK,IAAI,MAAM,MAAM,OAAO,IAAI,GAAG;AAC7D;AAEA;;;CAGC,GACD,SAAS,MAAM,KAAK;IAClB,OAAO,SAAS,OAAO,UAAU,WAAW,QAAQ;AACtD","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 81, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/initialize/content.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport {ok as assert} from 'devlop'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes, constants, types} from 'micromark-util-symbol'\n\n/** @type {InitialConstruct} */\nexport const content = {tokenize: initializeContent}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    return factorySpace(effects, contentStart, types.linePrefix)\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    assert(\n      code !== codes.eof && !markdownLineEnding(code),\n      'expected anything other than a line ending or EOF'\n    )\n    effects.enter(types.paragraph)\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(types.chunkText, {\n      contentType: constants.contentTypeText,\n      previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === codes.eof) {\n      effects.exit(types.chunkText)\n      effects.exit(types.paragraph)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit(types.chunkText)\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;CAQC;;;;AAED;AACA;AACA;AACA;AAAA;AAAA;;;;;AAGO,MAAM,UAAU;IAAC,UAAU;AAAiB;AAEnD;;;;;CAKC,GACD,SAAS,kBAAkB,OAAO;IAChC,MAAM,eAAe,QAAQ,OAAO,CAClC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,cAAc,EACrC,4BACA;IAEF,kBAAkB,GAClB,IAAI;IAEJ,OAAO;;;IAEP,kBAAkB,GAClB,SAAS,2BAA2B,IAAI;QACtC,IAAA,wLAAM,EACJ,SAAS,0MAAK,CAAC,GAAG,IAAI,IAAA,0NAAkB,EAAC,OACzC;QAGF,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,0MAAK,CAAC,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,0MAAK,CAAC,UAAU;QAC7B,OAAO,IAAA,mNAAY,EAAC,SAAS,cAAc,0MAAK,CAAC,UAAU;IAC7D;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,IAAA,wLAAM,EACJ,SAAS,0MAAK,CAAC,GAAG,IAAI,CAAC,IAAA,0NAAkB,EAAC,OAC1C;QAEF,QAAQ,KAAK,CAAC,0MAAK,CAAC,SAAS;QAC7B,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,MAAM,QAAQ,QAAQ,KAAK,CAAC,0MAAK,CAAC,SAAS,EAAE;YAC3C,aAAa,kNAAS,CAAC,eAAe;YACtC;QACF;QAEA,IAAI,UAAU;YACZ,SAAS,IAAI,GAAG;QAClB;QAEA,WAAW;QAEX,OAAO,KAAK;IACd;IAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;QAChB,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,QAAQ,IAAI,CAAC,0MAAK,CAAC,SAAS;YAC5B,QAAQ,IAAI,CAAC,0MAAK,CAAC,SAAS;YAC5B,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,IAAA,0NAAkB,EAAC,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,QAAQ,IAAI,CAAC,0MAAK,CAAC,SAAS;YAC5B,OAAO;QACT;QAEA,QAAQ;QACR,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;AACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 165, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/initialize/document.js"],"sourcesContent":["/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport {ok as assert} from 'devlop'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\nimport {codes, constants, types} from 'micromark-util-symbol'\n\n/** @type {InitialConstruct} */\nexport const document = {tokenize: initializeDocument}\n\n/** @type {Construct} */\nconst containerConstruct = {tokenize: tokenizeContainer}\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      assert(\n        item[0].continuation,\n        'expected `continuation` to be defined on container construct'\n      )\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined after continuation'\n    )\n\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = {...point}\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n\n      return checkNewContainers(code)\n    }\n\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    assert(\n      self.currentConstruct,\n      'expected `currentConstruct` to be defined on tokenizer'\n    )\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined on tokenizer'\n    )\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === codes.eof) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter(types.chunkFlow, {\n      _tokenizer: childFlow,\n      contentType: constants.contentTypeFlow,\n      previous: childToken\n    })\n\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === codes.eof) {\n      writeToChild(effects.exit(types.chunkFlow), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit(types.chunkFlow))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    assert(childFlow, 'expected `childFlow` to be defined when continuing')\n    const stream = self.sliceStream(token)\n    if (endOfFile) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n\n          seen = true\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = {...point}\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      assert(\n        entry[0].exit,\n        'expected `exit` to be defined on container construct'\n      )\n      entry[0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function closeFlow() {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined when closing flow'\n    )\n    assert(childFlow, 'expected `childFlow` to be defined when closing it')\n    childFlow.write([codes.eof])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n  assert(\n    this.parser.constructs.disable.null,\n    'expected `disable.null` to be populated'\n  )\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    types.linePrefix,\n    this.parser.constructs.disable.null.includes('codeIndented')\n      ? undefined\n      : constants.tabSize\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;CAYC,GAED;;;CAGC;;;;AAED;AACA;AACA;AACA;AACA;AAAA;AAAA;;;;;;AAGO,MAAM,WAAW;IAAC,UAAU;AAAkB;AAErD,sBAAsB,GACtB,MAAM,qBAAqB;IAAC,UAAU;AAAiB;AAEvD;;;;;CAKC,GACD,SAAS,mBAAmB,OAAO;IACjC,MAAM,OAAO,IAAI;IACjB,6BAA6B,GAC7B,MAAM,QAAQ,EAAE;IAChB,IAAI,YAAY;IAChB,wCAAwC,GACxC,IAAI;IACJ,8BAA8B,GAC9B,IAAI;IACJ,mBAAmB,GACnB,IAAI;IAEJ,OAAO;;;IAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;QACjB,mEAAmE;QACnE,uEAAuE;QACvE,SAAS;QACT,4EAA4E;QAC5E,kBAAkB;QAClB,uDAAuD;QACvD,yCAAyC;QACzC,kEAAkE;QAClE,uEAAuE;QACvE,qBAAqB;QACrB,IAAI,YAAY,MAAM,MAAM,EAAE;YAC5B,MAAM,OAAO,KAAK,CAAC,UAAU;YAC7B,KAAK,cAAc,GAAG,IAAI,CAAC,EAAE;YAC7B,IAAA,wLAAM,EACJ,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB;YAEF,OAAO,QAAQ,OAAO,CACpB,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB,kBACA,oBACA;QACJ;QAEA,QAAQ;QACR,OAAO,mBAAmB;IAC5B;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,IAAA,wLAAM,EACJ,KAAK,cAAc,EACnB;QAGF;QAEA,yEAAyE;QACzE,wEAAwE;QACxE,cAAc;QACd,IAAI,KAAK,cAAc,CAAC,UAAU,EAAE;YAClC,KAAK,cAAc,CAAC,UAAU,GAAG;YAEjC,IAAI,WAAW;gBACb;YACF;YAEA,kEAAkE;YAClE,4DAA4D;YAC5D,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,8BAA8B,GAC9B,IAAI;YAEJ,uBAAuB;YACvB,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,SAAS,EACxD;oBACA,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;oBAC3C;gBACF;YACF;YAEA,IAAA,wLAAM,EAAC,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,IAAI,QAAQ;YAEZ,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG;oBAAC,GAAG,KAAK;gBAAA;gBACrC;YACF;YAEA,4DAA4D;YAC5D,IAAA,4MAAM,EACJ,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;YAErB,OAAO,mBAAmB;QAC5B;QAEA,OAAO,MAAM;IACf;IAEA,kBAAkB,GAClB,SAAS,mBAAmB,IAAI;QAC9B,yEAAyE;QACzE,0DAA0D;QAC1D,sEAAsE;QACtE,sEAAsE;QACtE,SAAS;QACT,IAAI,cAAc,MAAM,MAAM,EAAE;YAC9B,sEAAsE;YACtE,iBAAiB;YACjB,qDAAqD;YACrD,IAAI,CAAC,WAAW;gBACd,OAAO,kBAAkB;YAC3B;YAEA,kEAAkE;YAClE,qEAAqE;YACrE,SAAS;YACT,IAAI,UAAU,gBAAgB,IAAI,UAAU,gBAAgB,CAAC,QAAQ,EAAE;gBACrE,OAAO,UAAU;YACnB;YAEA,sDAAsD;YACtD,sEAAsE;YACtE,aAAa;YACb,uEAAuE;YACvE,kDAAkD;YAClD,KAAK,SAAS,GAAG,QACf,UAAU,gBAAgB,IAAI,CAAC,UAAU,6BAA6B;QAE1E;QAEA,qCAAqC;QACrC,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,KAAK,CAClB,oBACA,sBACA,uBACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,qBAAqB,IAAI;QAChC,IAAI,WAAW;QACf,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,sBAAsB,IAAI;QACjC,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG,GAAG,IAAI,CAAC,GAAG,cAAc,MAAM,MAAM;QAC9D,kBAAkB,KAAK,GAAG,GAAG,MAAM;QACnC,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,sBAAsB;QACtB,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,OAAO,CACpB,oBACA,mBACA,WACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,IAAA,wLAAM,EACJ,KAAK,gBAAgB,EACrB;QAEF,IAAA,wLAAM,EACJ,KAAK,cAAc,EACnB;QAEF;QACA,MAAM,IAAI,CAAC;YAAC,KAAK,gBAAgB;YAAE,KAAK,cAAc;SAAC;QACvD,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,IAAI,WAAW;YACf,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,YAAY,aAAa,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG;QAClD,QAAQ,KAAK,CAAC,0MAAK,CAAC,SAAS,EAAE;YAC7B,YAAY;YACZ,aAAa,kNAAS,CAAC,eAAe;YACtC,UAAU;QACZ;QAEA,OAAO,aAAa;IACtB;IAEA,kBAAkB,GAClB,SAAS,aAAa,IAAI;QACxB,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,aAAa,QAAQ,IAAI,CAAC,0MAAK,CAAC,SAAS,GAAG;YAC5C,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,IAAA,0NAAkB,EAAC,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,aAAa,QAAQ,IAAI,CAAC,0MAAK,CAAC,SAAS;YACzC,+BAA+B;YAC/B,YAAY;YACZ,KAAK,SAAS,GAAG;YACjB,OAAO;QACT;QAEA,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;IAEA;;;;;;;GAOC,GACD,SAAS,aAAa,KAAK,EAAE,SAAS;QACpC,IAAA,wLAAM,EAAC,WAAW;QAClB,MAAM,SAAS,KAAK,WAAW,CAAC;QAChC,IAAI,WAAW,OAAO,IAAI,CAAC;QAC3B,MAAM,QAAQ,GAAG;QACjB,IAAI,YAAY,WAAW,IAAI,GAAG;QAClC,aAAa;QACb,UAAU,UAAU,CAAC,MAAM,KAAK;QAChC,UAAU,KAAK,CAAC;QAEhB,yCAAyC;QACzC,EAAE;QACF,cAAc;QACd,MAAM;QACN,KAAK;QACL,EAAE;QACF,MAAM;QACN,EAAE;QACF,SAAS;QACT,IAAI;QACJ,EAAE;QACF,MAAM;QACN,EAAE;QACF,UAAU;QACV,IAAI;QACJ,MAAM;QACN,EAAE;QACF,yEAAyE;QACzE,uEAAuE;QACvE,yCAAyC;QACzC,yEAAyE;QACzE,wDAAwD;QACxD,EAAE;QACF,qEAAqE;QACrE,qBAAqB;QACrB,oEAAoE;QACpE,uBAAuB;QACvB,yEAAyE;QACzE,8CAA8C;QAC9C,EAAE;QACF,sEAAsE;QACtE,kDAAkD;QAClD,yEAAyE;QACzE,IAAI,KAAK,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,IAAI,CAAC,EAAE;YACtC,IAAI,QAAQ,UAAU,MAAM,CAAC,MAAM;YAEnC,MAAO,QAAS;gBACd,IACE,2CAA2C;gBAC3C,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,MAAM,GAAG,mBAC1C,gCAAgC;gBAChC,CAAC,CAAC,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,IAC9B,qBAAqB;gBACrB,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,CAAC,MAAM,GAAG,eAAe,GACzD;oBACA,mEAAmE;oBACnE,qBAAqB;oBACrB;gBACF;YACF;YAEA,kEAAkE;YAClE,qDAAqD;YACrD,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,gCAAgC,GAChC,IAAI;YACJ,8BAA8B,GAC9B,IAAI;YAEJ,0DAA0D;YAC1D,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,SAAS,EACxD;oBACA,IAAI,MAAM;wBACR,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;wBAC3C;oBACF;oBAEA,OAAO;gBACT;YACF;YAEA,IAAA,wLAAM,EAAC,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,QAAQ;YAER,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG;oBAAC,GAAG,KAAK;gBAAA;gBACrC;YACF;YAEA,4DAA4D;YAC5D,IAAA,4MAAM,EACJ,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;QACvB;IACF;IAEA;;;;;GAKC,GACD,SAAS,eAAe,IAAI;QAC1B,IAAI,QAAQ,MAAM,MAAM;QAExB,wBAAwB;QACxB,MAAO,UAAU,KAAM;YACrB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAC1B,KAAK,cAAc,GAAG,KAAK,CAAC,EAAE;YAC9B,IAAA,wLAAM,EACJ,KAAK,CAAC,EAAE,CAAC,IAAI,EACb;YAEF,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;QAC3B;QAEA,MAAM,MAAM,GAAG;IACjB;IAEA,SAAS;QACP,IAAA,wLAAM,EACJ,KAAK,cAAc,EACnB;QAEF,IAAA,wLAAM,EAAC,WAAW;QAClB,UAAU,KAAK,CAAC;YAAC,0MAAK,CAAC,GAAG;SAAC;QAC3B,aAAa;QACb,YAAY;QACZ,KAAK,cAAc,CAAC,UAAU,GAAG;IACnC;AACF;AAEA;;;;;CAKC,GACD,SAAS,kBAAkB,OAAO,EAAE,EAAE,EAAE,GAAG;IACzC,gCAAgC;IAChC,IAAA,wLAAM,EACJ,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACnC;IAEF,OAAO,IAAA,mNAAY,EACjB,SACA,QAAQ,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,QAAQ,EAAE,IAAI,MACrD,0MAAK,CAAC,UAAU,EAChB,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,kBACzC,YACA,kNAAS,CAAC,OAAO;AAEzB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 501, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/initialize/flow.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport {ok as assert} from 'devlop'\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes, types} from 'micromark-util-symbol'\n\n/** @type {InitialConstruct} */\nexport const flow = {tokenize: initializeFlow}\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        types.linePrefix\n      )\n    )\n  )\n\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEndingBlank)\n    effects.consume(code)\n    effects.exit(types.lineEndingBlank)\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;CAOC;;;;AAED;AACA;AAAA;AACA;AACA;AACA;AAAA;;;;;;AAGO,MAAM,OAAO;IAAC,UAAU;AAAc;AAE7C;;;;;CAKC,GACD,SAAS,eAAe,OAAO;IAC7B,MAAM,OAAO,IAAI;IACjB,MAAM,UAAU,QAAQ,OAAO,CAC7B,6BAA6B;IAC7B,iOAAS,EACT,eACA,sDAAsD;IACtD,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,WAAW,EAClC,gBACA,IAAA,mNAAY,EACV,SACA,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAC3B,gBACA,QAAQ,OAAO,CAAC,yNAAO,EAAE,kBAE3B,0MAAK,CAAC,UAAU;IAKtB,OAAO;;;IAEP,kBAAkB,GAClB,SAAS,cAAc,IAAI;QACzB,IAAA,wLAAM,EACJ,SAAS,0MAAK,CAAC,GAAG,IAAI,IAAA,0NAAkB,EAAC,OACzC;QAGF,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,0MAAK,CAAC,eAAe;QACnC,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,0MAAK,CAAC,eAAe;QAClC,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;IAEA,kBAAkB,GAClB,SAAS,eAAe,IAAI;QAC1B,IAAA,wLAAM,EACJ,SAAS,0MAAK,CAAC,GAAG,IAAI,IAAA,0NAAkB,EAAC,OACzC;QAGF,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,0MAAK,CAAC,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,0MAAK,CAAC,UAAU;QAC7B,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;AACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 569, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/initialize/text.js"],"sourcesContent":["/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport {ok as assert} from 'devlop'\nimport {codes, constants, types} from 'micromark-util-symbol'\n\nexport const resolver = {resolveAll: createResolver()}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    ),\n    tokenize: initializeText\n  }\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === codes.eof) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter(types.data)\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(types.data)\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === codes.eof) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        // Always populated by defaults.\n        assert(Array.isArray(list), 'expected `disable.null` to be populated')\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === types.data) {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== types.data) {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === types.lineEnding) &&\n      events[eventIndex - 1][1].type === types.data\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === codes.space) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === codes.horizontalTab) {\n          tabs = true\n          size++\n        } else if (chunk === codes.virtualSpace) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      // Allow final trailing whitespace.\n      if (context._contentTypeTextTrailing && eventIndex === events.length) {\n        size = 0\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length ||\n            tabs ||\n            size < constants.hardBreakPrefixSizeMin\n              ? types.lineSuffix\n              : types.hardBreakTrailing,\n          start: {\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {...data.end}\n        }\n\n        data.end = {...token.start}\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;CASC;;;;;;;;AAED;AACA;AAAA;AAAA;;;AAEO,MAAM,WAAW;IAAC,YAAY;AAAgB;AAC9C,MAAM,SAAS,kBAAkB;AACjC,MAAM,OAAO,kBAAkB;AAEtC;;;;;CAKC,GACD,SAAS,kBAAkB,KAAK;IAC9B,OAAO;QACL,YAAY,eACV,UAAU,SAAS,yBAAyB;QAE9C,UAAU;IACZ;;;IAEA;;;;GAIC,GACD,SAAS,eAAe,OAAO;QAC7B,MAAM,OAAO,IAAI;QACjB,MAAM,aAAa,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,MAAM;QAChD,MAAM,OAAO,QAAQ,OAAO,CAAC,YAAY,OAAO;QAEhD,OAAO;;;QAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;YACjB,OAAO,QAAQ,QAAQ,KAAK,QAAQ,QAAQ;QAC9C;QAEA,kBAAkB,GAClB,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;gBACtB,QAAQ,OAAO,CAAC;gBAChB;YACF;YAEA,QAAQ,KAAK,CAAC,0MAAK,CAAC,IAAI;YACxB,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;YAChB,IAAI,QAAQ,OAAO;gBACjB,QAAQ,IAAI,CAAC,0MAAK,CAAC,IAAI;gBACvB,OAAO,KAAK;YACd;YAEA,QAAQ;YACR,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA;;;;;KAKC,GACD,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,0MAAK,CAAC,GAAG,EAAE;gBACtB,OAAO;YACT;YAEA,MAAM,OAAO,UAAU,CAAC,KAAK;YAC7B,IAAI,QAAQ,CAAC;YAEb,IAAI,MAAM;gBACR,gCAAgC;gBAChC,IAAA,wLAAM,EAAC,MAAM,OAAO,CAAC,OAAO;gBAE5B,MAAO,EAAE,QAAQ,KAAK,MAAM,CAAE;oBAC5B,MAAM,OAAO,IAAI,CAAC,MAAM;oBACxB,IAAI,CAAC,KAAK,QAAQ,IAAI,KAAK,QAAQ,CAAC,IAAI,CAAC,MAAM,KAAK,QAAQ,GAAG;wBAC7D,OAAO;oBACT;gBACF;YACF;YAEA,OAAO;QACT;IACF;AACF;AAEA;;;;;CAKC,GACD,SAAS,eAAe,aAAa;IACnC,OAAO;;;IAEP,qBAAqB,GACrB,SAAS,eAAe,MAAM,EAAE,OAAO;QACrC,IAAI,QAAQ,CAAC;QACb,+BAA+B,GAC/B,IAAI;QAEJ,sEAAsE;QACtE,kCAAkC;QAClC,MAAO,EAAE,SAAS,OAAO,MAAM,CAAE;YAC/B,IAAI,UAAU,WAAW;gBACvB,IAAI,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,IAAI,EAAE;oBACzD,QAAQ;oBACR;gBACF;YACF,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,IAAI,EAAE;gBACjE,gDAAgD;gBAChD,IAAI,UAAU,QAAQ,GAAG;oBACvB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,GAAG;oBAC/C,OAAO,MAAM,CAAC,QAAQ,GAAG,QAAQ,QAAQ;oBACzC,QAAQ,QAAQ;gBAClB;gBAEA,QAAQ;YACV;QACF;QAEA,OAAO,gBAAgB,cAAc,QAAQ,WAAW;IAC1D;AACF;AAEA;;;;;;;;;;CAUC,GACD,SAAS,uBAAuB,MAAM,EAAE,OAAO;IAC7C,IAAI,aAAa,EAAE,cAAc;;IAEjC,MAAO,EAAE,cAAc,OAAO,MAAM,CAAE;QACpC,IACE,CAAC,eAAe,OAAO,MAAM,IAC3B,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,UAAU,KACjD,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,IAAI,EAC7C;YACA,MAAM,OAAO,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE;YACtC,MAAM,SAAS,QAAQ,WAAW,CAAC;YACnC,IAAI,QAAQ,OAAO,MAAM;YACzB,IAAI,cAAc,CAAC;YACnB,IAAI,OAAO;YACX,gCAAgC,GAChC,IAAI;YAEJ,MAAO,QAAS;gBACd,MAAM,QAAQ,MAAM,CAAC,MAAM;gBAE3B,IAAI,OAAO,UAAU,UAAU;oBAC7B,cAAc,MAAM,MAAM;oBAE1B,MAAO,MAAM,UAAU,CAAC,cAAc,OAAO,0MAAK,CAAC,KAAK,CAAE;wBACxD;wBACA;oBACF;oBAEA,IAAI,aAAa;oBACjB,cAAc,CAAC;gBACjB,OAEK,IAAI,UAAU,0MAAK,CAAC,aAAa,EAAE;oBACtC,OAAO;oBACP;gBACF,OAAO,IAAI,UAAU,0MAAK,CAAC,YAAY,EAAE;gBACvC,QAAQ;gBACV,OAAO;oBACL,+BAA+B;oBAC/B;oBACA;gBACF;YACF;YAEA,mCAAmC;YACnC,IAAI,QAAQ,wBAAwB,IAAI,eAAe,OAAO,MAAM,EAAE;gBACpE,OAAO;YACT;YAEA,IAAI,MAAM;gBACR,MAAM,QAAQ;oBACZ,MACE,eAAe,OAAO,MAAM,IAC5B,QACA,OAAO,kNAAS,CAAC,sBAAsB,GACnC,0MAAK,CAAC,UAAU,GAChB,0MAAK,CAAC,iBAAiB;oBAC7B,OAAO;wBACL,cAAc,QACV,cACA,KAAK,KAAK,CAAC,YAAY,GAAG;wBAC9B,QAAQ,KAAK,KAAK,CAAC,MAAM,GAAG;wBAC5B,MAAM,KAAK,GAAG,CAAC,IAAI;wBACnB,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;oBAC5B;oBACA,KAAK;wBAAC,GAAG,KAAK,GAAG;oBAAA;gBACnB;gBAEA,KAAK,GAAG,GAAG;oBAAC,GAAG,MAAM,KAAK;gBAAA;gBAE1B,IAAI,KAAK,KAAK,CAAC,MAAM,KAAK,KAAK,GAAG,CAAC,MAAM,EAAE;oBACzC,OAAO,MAAM,CAAC,MAAM;gBACtB,OAAO;oBACL,OAAO,MAAM,CACX,YACA,GACA;wBAAC;wBAAS;wBAAO;qBAAQ,EACzB;wBAAC;wBAAQ;wBAAO;qBAAQ;oBAE1B,cAAc;gBAChB;YACF;YAEA;QACF;IACF;IAEA,OAAO;AACT","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 786, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/constructs.js"],"sourcesContent":["/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {codes} from 'micromark-util-symbol'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [codes.asterisk]: list,\n  [codes.plusSign]: list,\n  [codes.dash]: list,\n  [codes.digit0]: list,\n  [codes.digit1]: list,\n  [codes.digit2]: list,\n  [codes.digit3]: list,\n  [codes.digit4]: list,\n  [codes.digit5]: list,\n  [codes.digit6]: list,\n  [codes.digit7]: list,\n  [codes.digit8]: list,\n  [codes.digit9]: list,\n  [codes.greaterThan]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [codes.leftSquareBracket]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [codes.horizontalTab]: codeIndented,\n  [codes.virtualSpace]: codeIndented,\n  [codes.space]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [codes.numberSign]: headingAtx,\n  [codes.asterisk]: thematicBreak,\n  [codes.dash]: [setextUnderline, thematicBreak],\n  [codes.lessThan]: htmlFlow,\n  [codes.equalsTo]: setextUnderline,\n  [codes.underscore]: thematicBreak,\n  [codes.graveAccent]: codeFenced,\n  [codes.tilde]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [codes.ampersand]: characterReference,\n  [codes.backslash]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [codes.carriageReturn]: lineEnding,\n  [codes.lineFeed]: lineEnding,\n  [codes.carriageReturnLineFeed]: lineEnding,\n  [codes.exclamationMark]: labelStartImage,\n  [codes.ampersand]: characterReference,\n  [codes.asterisk]: attention,\n  [codes.lessThan]: [autolink, htmlText],\n  [codes.leftSquareBracket]: labelStartLink,\n  [codes.backslash]: [hardBreakEscape, characterEscape],\n  [codes.rightSquareBracket]: labelEnd,\n  [codes.underscore]: attention,\n  [codes.graveAccent]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {null: [attention, resolveText]}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {null: [codes.asterisk, codes.underscore]}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {null: []}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;;;;;;;;;;;AAED;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAsBA;AACA;;;;AAGO,MAAM,WAAW;IACtB,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,mNAAI;IACtB,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,mNAAI;IACtB,CAAC,0MAAK,CAAC,IAAI,CAAC,EAAE,mNAAI;IAClB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,MAAM,CAAC,EAAE,mNAAI;IACpB,CAAC,0MAAK,CAAC,WAAW,CAAC,EAAE,mOAAU;AACjC;AAGO,MAAM,iBAAiB;IAC5B,CAAC,0MAAK,CAAC,iBAAiB,CAAC,EAAE,+NAAU;AACvC;AAGO,MAAM,cAAc;IACzB,CAAC,0MAAK,CAAC,aAAa,CAAC,EAAE,uOAAY;IACnC,CAAC,0MAAK,CAAC,YAAY,CAAC,EAAE,uOAAY;IAClC,CAAC,0MAAK,CAAC,KAAK,CAAC,EAAE,uOAAY;AAC7B;AAGO,MAAM,OAAO;IAClB,CAAC,0MAAK,CAAC,UAAU,CAAC,EAAE,mOAAU;IAC9B,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,yOAAa;IAC/B,CAAC,0MAAK,CAAC,IAAI,CAAC,EAAE;QAAC,6OAAe;QAAE,yOAAa;KAAC;IAC9C,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,+NAAQ;IAC1B,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,6OAAe;IACjC,CAAC,0MAAK,CAAC,UAAU,CAAC,EAAE,yOAAa;IACjC,CAAC,0MAAK,CAAC,WAAW,CAAC,EAAE,mOAAU;IAC/B,CAAC,0MAAK,CAAC,KAAK,CAAC,EAAE,mOAAU;AAC3B;AAGO,MAAM,SAAS;IACpB,CAAC,0MAAK,CAAC,SAAS,CAAC,EAAE,mPAAkB;IACrC,CAAC,0MAAK,CAAC,SAAS,CAAC,EAAE,6OAAe;AACpC;AAGO,MAAM,OAAO;IAClB,CAAC,0MAAK,CAAC,cAAc,CAAC,EAAE,mOAAU;IAClC,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,mOAAU;IAC5B,CAAC,0MAAK,CAAC,sBAAsB,CAAC,EAAE,mOAAU;IAC1C,CAAC,0MAAK,CAAC,eAAe,CAAC,EAAE,iPAAe;IACxC,CAAC,0MAAK,CAAC,SAAS,CAAC,EAAE,mPAAkB;IACrC,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE,6NAAS;IAC3B,CAAC,0MAAK,CAAC,QAAQ,CAAC,EAAE;QAAC,2NAAQ;QAAE,+NAAQ;KAAC;IACtC,CAAC,0MAAK,CAAC,iBAAiB,CAAC,EAAE,+OAAc;IACzC,CAAC,0MAAK,CAAC,SAAS,CAAC,EAAE;QAAC,iPAAe;QAAE,6OAAe;KAAC;IACrD,CAAC,0MAAK,CAAC,kBAAkB,CAAC,EAAE,+NAAQ;IACpC,CAAC,0MAAK,CAAC,UAAU,CAAC,EAAE,6NAAS;IAC7B,CAAC,0MAAK,CAAC,WAAW,CAAC,EAAE,+NAAQ;AAC/B;AAGO,MAAM,aAAa;IAAC,MAAM;QAAC,6NAAS;QAAE,oQAAW;KAAC;AAAA;AAGlD,MAAM,mBAAmB;IAAC,MAAM;QAAC,0MAAK,CAAC,QAAQ;QAAE,0MAAK,CAAC,UAAU;KAAC;AAAA;AAGlE,MAAM,UAAU;IAAC,MAAM,EAAE;AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 913, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport createDebug from 'debug'\nimport {ok as assert} from 'devlop'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\nimport {codes, values} from 'micromark-util-symbol'\n\nconst debug = createDebug('micromark')\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: (from && from.line) || 1,\n    column: (from && from.column) || 1,\n    offset: (from && from.offset) || 0\n  }\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {interrupt: true})\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: codes.eof,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: codes.eof,\n    sliceSerialize,\n    sliceStream,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== codes.eof) {\n      return []\n    }\n\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {_bufferIndex, _index, line, column, offset} = point\n    return {_bufferIndex, _index, line, column, offset}\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n    debug('position: define skip: `%j`', point)\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    assert(consumed === true, 'expected character to be consumed')\n    consumed = undefined\n    debug('main: passing `%s` to %s', code, state && state.name)\n    expectedCode = code\n    assert(typeof state === 'function', 'expected state')\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    assert(code === expectedCode, 'expected given code to equal expected code')\n\n    debug('consume: `%s`', code)\n\n    assert(\n      consumed === undefined,\n      'expected code to not have been consumed: this might be because `return x(code)` instead of `return x` was used'\n    )\n    assert(\n      code === null\n        ? context.events.length === 0 ||\n            context.events[context.events.length - 1][0] === 'exit'\n        : context.events[context.events.length - 1][0] === 'enter',\n      'expected last token to be open'\n    )\n\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === codes.carriageReturnLineFeed ? 2 : 1\n      accountForPotentialSkip()\n      debug('position: after eol: `%j`', point)\n    } else if (code !== codes.virtualSpace) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      if (\n        point._bufferIndex ===\n        // Points w/ non-negative `_bufferIndex` reference\n        // strings.\n        /** @type {string} */ (chunks[point._index]).length\n      ) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n    debug('enter: `%s`', type)\n\n    context.events.push(['enter', token, context])\n\n    stack.push(token)\n\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n\n    const token = stack.pop()\n    assert(token, 'cannot close w/o open tokens')\n    token.end = now()\n\n    assert(type === token.type, 'expected exit token to match current token')\n\n    assert(\n      !(\n        token.start._index === token.end._index &&\n        token.start._bufferIndex === token.end._bufferIndex\n      ),\n      'expected non-empty token (`' + type + '`)'\n    )\n\n    debug('exit: `%s`', token.type)\n    context.events.push(['exit', token, context])\n\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n\n      return Array.isArray(constructs)\n        ? /* c8 ignore next 1 */\n          handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n          ? // Looks like a construct.\n            handleListOfConstructs([/** @type {Construct} */ (constructs)])\n          : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(left) ? left : left ? [left] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n\n        if (list.length === 0) {\n          assert(bogusState, 'expected `bogusState` to be given')\n          return bogusState\n        }\n\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n          assert(\n            context.parser.constructs.disable.null,\n            'expected `disable.null` to be populated'\n          )\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n\n    assert(\n      construct.partial ||\n        context.events.length === 0 ||\n        context.events[context.events.length - 1][0] === 'exit',\n      'expected last token to end'\n    )\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n\n    return {from: startEventsIndex, restore}\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n      debug('position: restore: `%j`', point)\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n\n  if (startIndex === endIndex) {\n    assert(endBufferIndex > -1, 'expected non-negative end buffer index')\n    assert(startBufferIndex > -1, 'expected non-negative start buffer index')\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n        /* c8 ignore next 4 -- used to be used, no longer */\n      } else {\n        assert(startBufferIndex === 0, 'expected `startBufferIndex` to be `0`')\n        view.shift()\n      }\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case codes.carriageReturn: {\n          value = values.cr\n\n          break\n        }\n\n        case codes.lineFeed: {\n          value = values.lf\n\n          break\n        }\n\n        case codes.carriageReturnLineFeed: {\n          value = values.cr + values.lf\n\n          break\n        }\n\n        case codes.horizontalTab: {\n          value = expandTabs ? values.space : values.ht\n\n          break\n        }\n\n        case codes.virtualSpace: {\n          if (!expandTabs && atTab) continue\n          value = values.space\n\n          break\n        }\n\n        default: {\n          assert(typeof chunk === 'number', 'expected number')\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n\n    atTab = chunk === codes.horizontalTab\n    result.push(value)\n  }\n\n  return result.join('')\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;CAcC,GAED;;;;;;;;;;;;;;;;;;;;;CAqBC;;;;AAED;AACA;AACA;AACA;AACA;AACA;AAAA;;;;;;;AAEA,MAAM,QAAQ,IAAA,sLAAW,EAAC;AAoBnB,SAAS,gBAAgB,MAAM,EAAE,UAAU,EAAE,IAAI;IACtD,kBAAkB,GAClB,IAAI,QAAQ;QACV,cAAc,CAAC;QACf,QAAQ;QACR,MAAM,AAAC,QAAQ,KAAK,IAAI,IAAK;QAC7B,QAAQ,AAAC,QAAQ,KAAK,MAAM,IAAK;QACjC,QAAQ,AAAC,QAAQ,KAAK,MAAM,IAAK;IACnC;IACA,mCAAmC,GACnC,MAAM,cAAc,CAAC;IACrB,6BAA6B,GAC7B,MAAM,uBAAuB,EAAE;IAC/B,yBAAyB,GACzB,IAAI,SAAS,EAAE;IACf,yBAAyB,GACzB,IAAI,QAAQ,EAAE;IACd,gCAAgC,GAChC,IAAI,WAAW;IAEf;;;;GAIC,GACD,MAAM,UAAU;QACd,SAAS,iBAAiB;QAC1B,OAAO,iBAAiB;QACxB;QACA;QACA;QACA,WAAW,iBAAiB,mBAAmB;YAAC,WAAW;QAAI;IACjE;IAEA;;;;GAIC,GACD,MAAM,UAAU;QACd,MAAM,0MAAK,CAAC,GAAG;QACf,gBAAgB,CAAC;QACjB;QACA,QAAQ,EAAE;QACV;QACA;QACA,UAAU,0MAAK,CAAC,GAAG;QACnB;QACA;QACA;IACF;IAEA;;;;GAIC,GACD,IAAI,QAAQ,WAAW,QAAQ,CAAC,IAAI,CAAC,SAAS;IAE9C;;;;GAIC,GACD,IAAI;IAEJ,IAAI,WAAW,UAAU,EAAE;QACzB,qBAAqB,IAAI,CAAC;IAC5B;IAEA,OAAO;;;IAEP,qCAAqC,GACrC,SAAS,MAAM,KAAK;QAClB,SAAS,IAAA,0MAAI,EAAC,QAAQ;QAEtB;QAEA,sDAAsD;QACtD,IAAI,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE,KAAK,0MAAK,CAAC,GAAG,EAAE;YAC3C,OAAO,EAAE;QACX;QAEA,UAAU,YAAY;QAEtB,gCAAgC;QAChC,QAAQ,MAAM,GAAG,IAAA,gNAAU,EAAC,sBAAsB,QAAQ,MAAM,EAAE;QAElE,OAAO,QAAQ,MAAM;IACvB;IAEA,EAAE;IACF,SAAS;IACT,EAAE;IAEF,8CAA8C,GAC9C,SAAS,eAAe,KAAK,EAAE,UAAU;QACvC,OAAO,gBAAgB,YAAY,QAAQ;IAC7C;IAEA,2CAA2C,GAC3C,SAAS,YAAY,KAAK;QACxB,OAAO,YAAY,QAAQ;IAC7B;IAEA,mCAAmC,GACnC,SAAS;QACP,iFAAiF;QACjF,MAAM,EAAC,YAAY,EAAE,MAAM,EAAE,IAAI,EAAE,MAAM,EAAE,MAAM,EAAC,GAAG;QACrD,OAAO;YAAC;YAAc;YAAQ;YAAM;YAAQ;QAAM;IACpD;IAEA,0CAA0C,GAC1C,SAAS,WAAW,KAAK;QACvB,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG,MAAM,MAAM;QACtC;QACA,MAAM,+BAA+B;IACvC;IAEA,EAAE;IACF,oBAAoB;IACpB,EAAE;IAEF;;;;;;;;;;GAUC,GACD,SAAS;QACP,mBAAmB,GACnB,IAAI;QAEJ,MAAO,MAAM,MAAM,GAAG,OAAO,MAAM,CAAE;YACnC,MAAM,QAAQ,MAAM,CAAC,MAAM,MAAM,CAAC;YAElC,+CAA+C;YAC/C,IAAI,OAAO,UAAU,UAAU;gBAC7B,aAAa,MAAM,MAAM;gBAEzB,IAAI,MAAM,YAAY,GAAG,GAAG;oBAC1B,MAAM,YAAY,GAAG;gBACvB;gBAEA,MACE,MAAM,MAAM,KAAK,cACjB,MAAM,YAAY,GAAG,MAAM,MAAM,CACjC;oBACA,GAAG,MAAM,UAAU,CAAC,MAAM,YAAY;gBACxC;YACF,OAAO;gBACL,GAAG;YACL;QACF;IACF;IAEA;;;;;;;GAOC,GACD,SAAS,GAAG,IAAI;QACd,IAAA,wLAAM,EAAC,aAAa,MAAM;QAC1B,WAAW;QACX,MAAM,4BAA4B,MAAM,SAAS,MAAM,IAAI;QAC3D,eAAe;QACf,IAAA,wLAAM,EAAC,OAAO,UAAU,YAAY;QACpC,QAAQ,MAAM;IAChB;IAEA,+BAA+B,GAC/B,SAAS,QAAQ,IAAI;QACnB,IAAA,wLAAM,EAAC,SAAS,cAAc;QAE9B,MAAM,iBAAiB;QAEvB,IAAA,wLAAM,EACJ,aAAa,WACb;QAEF,IAAA,wLAAM,EACJ,SAAS,OACL,QAAQ,MAAM,CAAC,MAAM,KAAK,KACxB,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACnD,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACrD;QAGF,IAAI,IAAA,0NAAkB,EAAC,OAAO;YAC5B,MAAM,IAAI;YACV,MAAM,MAAM,GAAG;YACf,MAAM,MAAM,IAAI,SAAS,0MAAK,CAAC,sBAAsB,GAAG,IAAI;YAC5D;YACA,MAAM,6BAA6B;QACrC,OAAO,IAAI,SAAS,0MAAK,CAAC,YAAY,EAAE;YACtC,MAAM,MAAM;YACZ,MAAM,MAAM;QACd;QAEA,yBAAyB;QACzB,IAAI,MAAM,YAAY,GAAG,GAAG;YAC1B,MAAM,MAAM;QACd,OAAO;YACL,MAAM,YAAY;YAElB,0BAA0B;YAC1B,IACE,MAAM,YAAY,KAClB,kDAAkD;YAClD,WAAW;YACX,mBAAmB,GAAG,AAAC,MAAM,CAAC,MAAM,MAAM,CAAC,CAAE,MAAM,EACnD;gBACA,MAAM,YAAY,GAAG,CAAC;gBACtB,MAAM,MAAM;YACd;QACF;QAEA,iCAAiC;QACjC,QAAQ,QAAQ,GAAG;QAEnB,oBAAoB;QACpB,WAAW;IACb;IAEA,6BAA6B,GAC7B,SAAS,MAAM,IAAI,EAAE,MAAM;QACzB,kBAAkB,GAClB,uEAAuE;QACvE,MAAM,QAAQ,UAAU,CAAC;QACzB,MAAM,IAAI,GAAG;QACb,MAAM,KAAK,GAAG;QAEd,IAAA,wLAAM,EAAC,OAAO,SAAS,UAAU;QACjC,IAAA,wLAAM,EAAC,KAAK,MAAM,GAAG,GAAG;QACxB,MAAM,eAAe;QAErB,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAS;YAAO;SAAQ;QAE7C,MAAM,IAAI,CAAC;QAEX,OAAO;IACT;IAEA,4BAA4B,GAC5B,SAAS,KAAK,IAAI;QAChB,IAAA,wLAAM,EAAC,OAAO,SAAS,UAAU;QACjC,IAAA,wLAAM,EAAC,KAAK,MAAM,GAAG,GAAG;QAExB,MAAM,QAAQ,MAAM,GAAG;QACvB,IAAA,wLAAM,EAAC,OAAO;QACd,MAAM,GAAG,GAAG;QAEZ,IAAA,wLAAM,EAAC,SAAS,MAAM,IAAI,EAAE;QAE5B,IAAA,wLAAM,EACJ,CAAC,CACC,MAAM,KAAK,CAAC,MAAM,KAAK,MAAM,GAAG,CAAC,MAAM,IACvC,MAAM,KAAK,CAAC,YAAY,KAAK,MAAM,GAAG,CAAC,YAAY,AACrD,GACA,gCAAgC,OAAO;QAGzC,MAAM,cAAc,MAAM,IAAI;QAC9B,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAQ;YAAO;SAAQ;QAE5C,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,sBAAsB,SAAS,EAAE,IAAI;QAC5C,UAAU,WAAW,KAAK,IAAI;IAChC;IAEA;;;;GAIC,GACD,SAAS,kBAAkB,CAAC,EAAE,IAAI;QAChC,KAAK,OAAO;IACd;IAEA;;;;;;;GAOC,GACD,SAAS,iBAAiB,QAAQ,EAAE,MAAM;QACxC,OAAO;;;QAEP;;;;;;;;;;;;KAYC,GACD,SAAS,KAAK,UAAU,EAAE,WAAW,EAAE,UAAU;YAC/C,qCAAqC,GACrC,IAAI;YACJ,mBAAmB,GACnB,IAAI;YACJ,sBAAsB,GACtB,IAAI;YACJ,iBAAiB,GACjB,IAAI;YAEJ,OAAO,MAAM,OAAO,CAAC,cACjB,oBAAoB,GACpB,uBAAuB,cACvB,cAAc,aAEZ,uBAAuB;gBAA2B;aAAY,IAC9D,sBAAsB;;;YAE5B;;;;;;;OAOC,GACD,SAAS,sBAAsB,GAAG;gBAChC,OAAO;;;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,MAAM,OAAO,SAAS,QAAQ,GAAG,CAAC,KAAK;oBACvC,MAAM,MAAM,SAAS,QAAQ,IAAI,IAAI;oBACrC,MAAM,OAAO;wBACX,mCAAmC;wBACnC,oBAAoB,MAChB,MAAM,OAAO,CAAC,QAAQ,OAAO,OAAO;4BAAC;yBAAK,GAAG,EAAE;2BAC/C,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;qBAChD;oBAED,OAAO,uBAAuB,MAAM;gBACtC;YACF;YAEA;;;;;;;OAOC,GACD,SAAS,uBAAuB,IAAI;gBAClC,mBAAmB;gBACnB,iBAAiB;gBAEjB,IAAI,KAAK,MAAM,KAAK,GAAG;oBACrB,IAAA,wLAAM,EAAC,YAAY;oBACnB,OAAO;gBACT;gBAEA,OAAO,gBAAgB,IAAI,CAAC,eAAe;YAC7C;YAEA;;;;;;;OAOC,GACD,SAAS,gBAAgB,SAAS;gBAChC,OAAO;;;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,mEAAmE;oBACnE,oEAAoE;oBACpE,uEAAuE;oBACvE,kBAAkB;oBAClB,OAAO;oBACP,mBAAmB;oBAEnB,IAAI,CAAC,UAAU,OAAO,EAAE;wBACtB,QAAQ,gBAAgB,GAAG;oBAC7B;oBAEA,gCAAgC;oBAChC,IAAA,wLAAM,EACJ,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACtC;oBAGF,IACE,UAAU,IAAI,IACd,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,IAAI,GAC9D;wBACA,OAAO,IAAI;oBACb;oBAEA,OAAO,UAAU,QAAQ,CAAC,IAAI,CAC5B,6DAA6D;oBAC7D,aAAa;oBACb,iEAAiE;oBACjE,SAAS,OAAO,MAAM,CAAC,OAAO,MAAM,CAAC,UAAU,UAAU,SACzD,SACA,IACA,KACA;gBACJ;YACF;YAEA,kBAAkB,GAClB,SAAS,GAAG,IAAI;gBACd,IAAA,wLAAM,EAAC,SAAS,cAAc;gBAC9B,WAAW;gBACX,SAAS,kBAAkB;gBAC3B,OAAO;YACT;YAEA,kBAAkB,GAClB,SAAS,IAAI,IAAI;gBACf,IAAA,wLAAM,EAAC,SAAS,cAAc;gBAC9B,WAAW;gBACX,KAAK,OAAO;gBAEZ,IAAI,EAAE,iBAAiB,iBAAiB,MAAM,EAAE;oBAC9C,OAAO,gBAAgB,gBAAgB,CAAC,eAAe;gBACzD;gBAEA,OAAO;YACT;QACF;IACF;IAEA;;;;;;;GAOC,GACD,SAAS,UAAU,SAAS,EAAE,IAAI;QAChC,IAAI,UAAU,UAAU,IAAI,CAAC,qBAAqB,QAAQ,CAAC,YAAY;YACrE,qBAAqB,IAAI,CAAC;QAC5B;QAEA,IAAI,UAAU,OAAO,EAAE;YACrB,IAAA,4MAAM,EACJ,QAAQ,MAAM,EACd,MACA,QAAQ,MAAM,CAAC,MAAM,GAAG,MACxB,UAAU,OAAO,CAAC,QAAQ,MAAM,CAAC,KAAK,CAAC,OAAO;QAElD;QAEA,IAAI,UAAU,SAAS,EAAE;YACvB,QAAQ,MAAM,GAAG,UAAU,SAAS,CAAC,QAAQ,MAAM,EAAE;QACvD;QAEA,IAAA,wLAAM,EACJ,UAAU,OAAO,IACf,QAAQ,MAAM,CAAC,MAAM,KAAK,KAC1B,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,QACnD;IAEJ;IAEA;;;;;GAKC,GACD,SAAS;QACP,MAAM,aAAa;QACnB,MAAM,gBAAgB,QAAQ,QAAQ;QACtC,MAAM,wBAAwB,QAAQ,gBAAgB;QACtD,MAAM,mBAAmB,QAAQ,MAAM,CAAC,MAAM;QAC9C,MAAM,aAAa,MAAM,IAAI,CAAC;QAE9B,OAAO;YAAC,MAAM;YAAkB;QAAO;;;QAEvC;;;;;KAKC,GACD,SAAS;YACP,QAAQ;YACR,QAAQ,QAAQ,GAAG;YACnB,QAAQ,gBAAgB,GAAG;YAC3B,QAAQ,MAAM,CAAC,MAAM,GAAG;YACxB,QAAQ;YACR;YACA,MAAM,2BAA2B;QACnC;IACF;IAEA;;;;;;GAMC,GACD,SAAS;QACP,IAAI,MAAM,IAAI,IAAI,eAAe,MAAM,MAAM,GAAG,GAAG;YACjD,MAAM,MAAM,GAAG,WAAW,CAAC,MAAM,IAAI,CAAC;YACtC,MAAM,MAAM,IAAI,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG;QAC5C;IACF;AACF;AAEA;;;;;;;;;CASC,GACD,SAAS,YAAY,MAAM,EAAE,KAAK;IAChC,MAAM,aAAa,MAAM,KAAK,CAAC,MAAM;IACrC,MAAM,mBAAmB,MAAM,KAAK,CAAC,YAAY;IACjD,MAAM,WAAW,MAAM,GAAG,CAAC,MAAM;IACjC,MAAM,iBAAiB,MAAM,GAAG,CAAC,YAAY;IAC7C,yBAAyB,GACzB,IAAI;IAEJ,IAAI,eAAe,UAAU;QAC3B,IAAA,wLAAM,EAAC,iBAAiB,CAAC,GAAG;QAC5B,IAAA,wLAAM,EAAC,mBAAmB,CAAC,GAAG;QAC9B,4DAA4D;QAC5D,OAAO;YAAC,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,kBAAkB;SAAgB;IACrE,OAAO;QACL,OAAO,OAAO,KAAK,CAAC,YAAY;QAEhC,IAAI,mBAAmB,CAAC,GAAG;YACzB,MAAM,OAAO,IAAI,CAAC,EAAE;YACpB,IAAI,OAAO,SAAS,UAAU;gBAC5B,IAAI,CAAC,EAAE,GAAG,KAAK,KAAK,CAAC;YACrB,kDAAkD,GACpD,OAAO;gBACL,IAAA,wLAAM,EAAC,qBAAqB,GAAG;gBAC/B,KAAK,KAAK;YACZ;QACF;QAEA,IAAI,iBAAiB,GAAG;YACtB,4DAA4D;YAC5D,KAAK,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG;QACtC;IACF;IAEA,OAAO;AACT;AAEA;;;;;;;;;CASC,GACD,SAAS,gBAAgB,MAAM,EAAE,UAAU;IACzC,IAAI,QAAQ,CAAC;IACb,0BAA0B,GAC1B,MAAM,SAAS,EAAE;IACjB,gCAAgC,GAChC,IAAI;IAEJ,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;QAC9B,MAAM,QAAQ,MAAM,CAAC,MAAM;QAC3B,mBAAmB,GACnB,IAAI;QAEJ,IAAI,OAAO,UAAU,UAAU;YAC7B,QAAQ;QACV,OACE,OAAQ;YACN,KAAK,0MAAK,CAAC,cAAc;gBAAE;oBACzB,QAAQ,4MAAM,CAAC,EAAE;oBAEjB;gBACF;YAEA,KAAK,0MAAK,CAAC,QAAQ;gBAAE;oBACnB,QAAQ,4MAAM,CAAC,EAAE;oBAEjB;gBACF;YAEA,KAAK,0MAAK,CAAC,sBAAsB;gBAAE;oBACjC,QAAQ,4MAAM,CAAC,EAAE,GAAG,4MAAM,CAAC,EAAE;oBAE7B;gBACF;YAEA,KAAK,0MAAK,CAAC,aAAa;gBAAE;oBACxB,QAAQ,aAAa,4MAAM,CAAC,KAAK,GAAG,4MAAM,CAAC,EAAE;oBAE7C;gBACF;YAEA,KAAK,0MAAK,CAAC,YAAY;gBAAE;oBACvB,IAAI,CAAC,cAAc,OAAO;oBAC1B,QAAQ,4MAAM,CAAC,KAAK;oBAEpB;gBACF;YAEA;gBAAS;oBACP,IAAA,wLAAM,EAAC,OAAO,UAAU,UAAU;oBAClC,wCAAwC;oBACxC,QAAQ,OAAO,YAAY,CAAC;gBAC9B;QACF;QAEF,QAAQ,UAAU,0MAAK,CAAC,aAAa;QACrC,OAAO,IAAI,CAAC;IACd;IAEA,OAAO,OAAO,IAAI,CAAC;AACrB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1476, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/parse.js"],"sourcesContent":["/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {string, text} from './initialize/text.js'\nimport * as defaultConstructs from './constructs.js'\nimport {createTokenizer} from './create-tokenizer.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs = /** @type {FullNormalizedExtension} */ (\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n  )\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  }\n\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;CAQC;;;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AAQO,SAAS,MAAM,OAAO;IAC3B,MAAM,WAAW,WAAW,CAAC;IAC7B,MAAM,aACJ,IAAA,8NAAiB,EAAC;QAAC;WAAuB,SAAS,UAAU,IAAI,EAAE;KAAE;IAGvE,yBAAyB,GACzB,MAAM,SAAS;QACb;QACA,SAAS,OAAO,sQAAO;QACvB,SAAS,EAAE;QACX,UAAU,OAAO,wQAAQ;QACzB,MAAM,OAAO,gQAAI;QACjB,MAAM,CAAC;QACP,QAAQ,OAAO,kQAAM;QACrB,MAAM,OAAO,gQAAI;IACnB;IAEA,OAAO;;;IAEP;;;;;GAKC,GACD,SAAS,OAAO,OAAO;QACrB,OAAO;;;QACP,mBAAmB,GACnB,SAAS,QAAQ,IAAI;YACnB,OAAO,IAAA,4QAAe,EAAC,QAAQ,SAAS;QAC1C;IACF;AACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1539, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/postprocess.js"],"sourcesContent":["/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;AAED;;AAQO,SAAS,YAAY,MAAM;IAChC,MAAO,CAAC,IAAA,0RAAW,EAAC,QAAS;IAC3B,QAAQ;IACV;IAEA,OAAO;AACT","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1557, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark/dev/lib/preprocess.js"],"sourcesContent":["/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nimport {codes, constants} from 'micromark-util-symbol'\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    value =\n      buffer +\n      (typeof value === 'string'\n        ? value.toString()\n        : new TextDecoder(encoding || undefined).decode(value))\n\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === codes.byteOrderMarker) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (\n        code === codes.lf &&\n        startPosition === endPosition &&\n        atCarriageReturn\n      ) {\n        chunks.push(codes.carriageReturnLineFeed)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(codes.carriageReturn)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        switch (code) {\n          case codes.nul: {\n            chunks.push(codes.replacementCharacter)\n            column++\n\n            break\n          }\n\n          case codes.ht: {\n            next = Math.ceil(column / constants.tabSize) * constants.tabSize\n            chunks.push(codes.horizontalTab)\n            while (column++ < next) chunks.push(codes.virtualSpace)\n\n            break\n          }\n\n          case codes.lf: {\n            chunks.push(codes.lineFeed)\n            column = 1\n\n            break\n          }\n\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(codes.carriageReturn)\n      if (buffer) chunks.push(buffer)\n      chunks.push(codes.eof)\n    }\n\n    return chunks\n  }\n}\n"],"names":[],"mappings":"AAAA;;CAEC,GAED;;;;;;;;;;;CAWC;;;;AAED;AAAA;;AAEA,MAAM,SAAS;AAMR,SAAS;IACd,IAAI,SAAS;IACb,IAAI,SAAS;IACb,gCAAgC,GAChC,IAAI,QAAQ;IACZ,gCAAgC,GAChC,IAAI;IAEJ,OAAO;;;IAEP,yBAAyB,GACzB,sCAAsC;IACtC,SAAS,aAAa,KAAK,EAAE,QAAQ,EAAE,GAAG;QACxC,yBAAyB,GACzB,MAAM,SAAS,EAAE;QACjB,oCAAoC,GACpC,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,iBAAiB,GACjB,IAAI;QAEJ,QACE,SACA,CAAC,OAAO,UAAU,WACd,MAAM,QAAQ,KACd,IAAI,YAAY,YAAY,WAAW,MAAM,CAAC,MAAM;QAE1D,gBAAgB;QAChB,SAAS;QAET,IAAI,OAAO;YACT,+DAA+D;YAC/D,IAAI,MAAM,UAAU,CAAC,OAAO,0MAAK,CAAC,eAAe,EAAE;gBACjD;YACF;YAEA,QAAQ;QACV;QAEA,MAAO,gBAAgB,MAAM,MAAM,CAAE;YACnC,OAAO,SAAS,GAAG;YACnB,QAAQ,OAAO,IAAI,CAAC;YACpB,cACE,SAAS,MAAM,KAAK,KAAK,YAAY,MAAM,KAAK,GAAG,MAAM,MAAM;YACjE,OAAO,MAAM,UAAU,CAAC;YAExB,IAAI,CAAC,OAAO;gBACV,SAAS,MAAM,KAAK,CAAC;gBACrB;YACF;YAEA,IACE,SAAS,0MAAK,CAAC,EAAE,IACjB,kBAAkB,eAClB,kBACA;gBACA,OAAO,IAAI,CAAC,0MAAK,CAAC,sBAAsB;gBACxC,mBAAmB;YACrB,OAAO;gBACL,IAAI,kBAAkB;oBACpB,OAAO,IAAI,CAAC,0MAAK,CAAC,cAAc;oBAChC,mBAAmB;gBACrB;gBAEA,IAAI,gBAAgB,aAAa;oBAC/B,OAAO,IAAI,CAAC,MAAM,KAAK,CAAC,eAAe;oBACvC,UAAU,cAAc;gBAC1B;gBAEA,OAAQ;oBACN,KAAK,0MAAK,CAAC,GAAG;wBAAE;4BACd,OAAO,IAAI,CAAC,0MAAK,CAAC,oBAAoB;4BACtC;4BAEA;wBACF;oBAEA,KAAK,0MAAK,CAAC,EAAE;wBAAE;4BACb,OAAO,KAAK,IAAI,CAAC,SAAS,kNAAS,CAAC,OAAO,IAAI,kNAAS,CAAC,OAAO;4BAChE,OAAO,IAAI,CAAC,0MAAK,CAAC,aAAa;4BAC/B,MAAO,WAAW,KAAM,OAAO,IAAI,CAAC,0MAAK,CAAC,YAAY;4BAEtD;wBACF;oBAEA,KAAK,0MAAK,CAAC,EAAE;wBAAE;4BACb,OAAO,IAAI,CAAC,0MAAK,CAAC,QAAQ;4BAC1B,SAAS;4BAET;wBACF;oBAEA;wBAAS;4BACP,mBAAmB;4BACnB,SAAS;wBACX;gBACF;YACF;YAEA,gBAAgB,cAAc;QAChC;QAEA,IAAI,KAAK;YACP,IAAI,kBAAkB,OAAO,IAAI,CAAC,0MAAK,CAAC,cAAc;YACtD,IAAI,QAAQ,OAAO,IAAI,CAAC;YACxB,OAAO,IAAI,CAAC,0MAAK,CAAC,GAAG;QACvB;QAEA,OAAO;IACT;AACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1666, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark-util-subtokenize/dev/lib/splice-buffer.js"],"sourcesContent":["import {constants} from 'micromark-util-symbol'\n\n/**\n * Some of the internal operations of micromark do lots of editing\n * operations on very large arrays. This runs into problems with two\n * properties of most circa-2020 JavaScript interpreters:\n *\n *  - Array-length modifications at the high end of an array (push/pop) are\n *    expected to be common and are implemented in (amortized) time\n *    proportional to the number of elements added or removed, whereas\n *    other operations (shift/unshift and splice) are much less efficient.\n *  - Function arguments are passed on the stack, so adding tens of thousands\n *    of elements to an array with `arr.push(...newElements)` will frequently\n *    cause stack overflows. (see <https://stackoverflow.com/questions/22123769/rangeerror-maximum-call-stack-size-exceeded-why>)\n *\n * SpliceBuffers are an implementation of gap buffers, which are a\n * generalization of the \"queue made of two stacks\" idea. The splice buffer\n * maintains a cursor, and moving the cursor has cost proportional to the\n * distance the cursor moves, but inserting, deleting, or splicing in\n * new information at the cursor is as efficient as the push/pop operation.\n * This allows for an efficient sequence of splices (or pushes, pops, shifts,\n * or unshifts) as long such edits happen at the same part of the array or\n * generally sweep through the array from the beginning to the end.\n *\n * The interface for splice buffers also supports large numbers of inputs by\n * passing a single array argument rather passing multiple arguments on the\n * function call stack.\n *\n * @template T\n *   Item type.\n */\nexport class SpliceBuffer {\n  /**\n   * @param {ReadonlyArray<T> | null | undefined} [initial]\n   *   Initial items (optional).\n   * @returns\n   *   Splice buffer.\n   */\n  constructor(initial) {\n    /** @type {Array<T>} */\n    this.left = initial ? [...initial] : []\n    /** @type {Array<T>} */\n    this.right = []\n  }\n\n  /**\n   * Array access;\n   * does not move the cursor.\n   *\n   * @param {number} index\n   *   Index.\n   * @return {T}\n   *   Item.\n   */\n  get(index) {\n    if (index < 0 || index >= this.left.length + this.right.length) {\n      throw new RangeError(\n        'Cannot access index `' +\n          index +\n          '` in a splice buffer of size `' +\n          (this.left.length + this.right.length) +\n          '`'\n      )\n    }\n\n    if (index < this.left.length) return this.left[index]\n    return this.right[this.right.length - index + this.left.length - 1]\n  }\n\n  /**\n   * The length of the splice buffer, one greater than the largest index in the\n   * array.\n   */\n  get length() {\n    return this.left.length + this.right.length\n  }\n\n  /**\n   * Remove and return `list[0]`;\n   * moves the cursor to `0`.\n   *\n   * @returns {T | undefined}\n   *   Item, optional.\n   */\n  shift() {\n    this.setCursor(0)\n    return this.right.pop()\n  }\n\n  /**\n   * Slice the buffer to get an array;\n   * does not move the cursor.\n   *\n   * @param {number} start\n   *   Start.\n   * @param {number | null | undefined} [end]\n   *   End (optional).\n   * @returns {Array<T>}\n   *   Array of items.\n   */\n  slice(start, end) {\n    /** @type {number} */\n    const stop =\n      end === null || end === undefined ? Number.POSITIVE_INFINITY : end\n\n    if (stop < this.left.length) {\n      return this.left.slice(start, stop)\n    }\n\n    if (start > this.left.length) {\n      return this.right\n        .slice(\n          this.right.length - stop + this.left.length,\n          this.right.length - start + this.left.length\n        )\n        .reverse()\n    }\n\n    return this.left\n      .slice(start)\n      .concat(\n        this.right.slice(this.right.length - stop + this.left.length).reverse()\n      )\n  }\n\n  /**\n   * Mimics the behavior of Array.prototype.splice() except for the change of\n   * interface necessary to avoid segfaults when patching in very large arrays.\n   *\n   * This operation moves cursor is moved to `start` and results in the cursor\n   * placed after any inserted items.\n   *\n   * @param {number} start\n   *   Start;\n   *   zero-based index at which to start changing the array;\n   *   negative numbers count backwards from the end of the array and values\n   *   that are out-of bounds are clamped to the appropriate end of the array.\n   * @param {number | null | undefined} [deleteCount=0]\n   *   Delete count (default: `0`);\n   *   maximum number of elements to delete, starting from start.\n   * @param {Array<T> | null | undefined} [items=[]]\n   *   Items to include in place of the deleted items (default: `[]`).\n   * @return {Array<T>}\n   *   Any removed items.\n   */\n  splice(start, deleteCount, items) {\n    /** @type {number} */\n    const count = deleteCount || 0\n\n    this.setCursor(Math.trunc(start))\n    const removed = this.right.splice(\n      this.right.length - count,\n      Number.POSITIVE_INFINITY\n    )\n    if (items) chunkedPush(this.left, items)\n    return removed.reverse()\n  }\n\n  /**\n   * Remove and return the highest-numbered item in the array, so\n   * `list[list.length - 1]`;\n   * Moves the cursor to `length`.\n   *\n   * @returns {T | undefined}\n   *   Item, optional.\n   */\n  pop() {\n    this.setCursor(Number.POSITIVE_INFINITY)\n    return this.left.pop()\n  }\n\n  /**\n   * Inserts a single item to the high-numbered side of the array;\n   * moves the cursor to `length`.\n   *\n   * @param {T} item\n   *   Item.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  push(item) {\n    this.setCursor(Number.POSITIVE_INFINITY)\n    this.left.push(item)\n  }\n\n  /**\n   * Inserts many items to the high-numbered side of the array.\n   * Moves the cursor to `length`.\n   *\n   * @param {Array<T>} items\n   *   Items.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  pushMany(items) {\n    this.setCursor(Number.POSITIVE_INFINITY)\n    chunkedPush(this.left, items)\n  }\n\n  /**\n   * Inserts a single item to the low-numbered side of the array;\n   * Moves the cursor to `0`.\n   *\n   * @param {T} item\n   *   Item.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  unshift(item) {\n    this.setCursor(0)\n    this.right.push(item)\n  }\n\n  /**\n   * Inserts many items to the low-numbered side of the array;\n   * moves the cursor to `0`.\n   *\n   * @param {Array<T>} items\n   *   Items.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  unshiftMany(items) {\n    this.setCursor(0)\n    chunkedPush(this.right, items.reverse())\n  }\n\n  /**\n   * Move the cursor to a specific position in the array. Requires\n   * time proportional to the distance moved.\n   *\n   * If `n < 0`, the cursor will end up at the beginning.\n   * If `n > length`, the cursor will end up at the end.\n   *\n   * @param {number} n\n   *   Position.\n   * @return {undefined}\n   *   Nothing.\n   */\n  setCursor(n) {\n    if (\n      n === this.left.length ||\n      (n > this.left.length && this.right.length === 0) ||\n      (n < 0 && this.left.length === 0)\n    )\n      return\n    if (n < this.left.length) {\n      // Move cursor to the this.left\n      const removed = this.left.splice(n, Number.POSITIVE_INFINITY)\n      chunkedPush(this.right, removed.reverse())\n    } else {\n      // Move cursor to the this.right\n      const removed = this.right.splice(\n        this.left.length + this.right.length - n,\n        Number.POSITIVE_INFINITY\n      )\n      chunkedPush(this.left, removed.reverse())\n    }\n  }\n}\n\n/**\n * Avoid stack overflow by pushing items onto the stack in segments\n *\n * @template T\n *   Item type.\n * @param {Array<T>} list\n *   List to inject into.\n * @param {ReadonlyArray<T>} right\n *   Items to inject.\n * @return {undefined}\n *   Nothing.\n */\nfunction chunkedPush(list, right) {\n  /** @type {number} */\n  let chunkStart = 0\n\n  if (right.length < constants.v8MaxSafeChunkSize) {\n    list.push(...right)\n  } else {\n    while (chunkStart < right.length) {\n      list.push(\n        ...right.slice(chunkStart, chunkStart + constants.v8MaxSafeChunkSize)\n      )\n      chunkStart += constants.v8MaxSafeChunkSize\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;AA+BO,MAAM;IACX;;;;;GAKC,GACD,YAAY,OAAO,CAAE;QACnB,qBAAqB,GACrB,IAAI,CAAC,IAAI,GAAG,UAAU;eAAI;SAAQ,GAAG,EAAE;QACvC,qBAAqB,GACrB,IAAI,CAAC,KAAK,GAAG,EAAE;IACjB;IAEA;;;;;;;;GAQC,GACD,IAAI,KAAK,EAAE;QACT,IAAI,QAAQ,KAAK,SAAS,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE;YAC9D,MAAM,IAAI,WACR,0BACE,QACA,mCACA,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,IACrC;QAEN;QAEA,IAAI,QAAQ,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM;QACrD,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,QAAQ,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,EAAE;IACrE;IAEA;;;GAGC,GACD,IAAI,SAAS;QACX,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM;IAC7C;IAEA;;;;;;GAMC,GACD,QAAQ;QACN,IAAI,CAAC,SAAS,CAAC;QACf,OAAO,IAAI,CAAC,KAAK,CAAC,GAAG;IACvB;IAEA;;;;;;;;;;GAUC,GACD,MAAM,KAAK,EAAE,GAAG,EAAE;QAChB,mBAAmB,GACnB,MAAM,OACJ,QAAQ,QAAQ,QAAQ,YAAY,OAAO,iBAAiB,GAAG;QAEjE,IAAI,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO;QAChC;QAEA,IAAI,QAAQ,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAC5B,OAAO,IAAI,CAAC,KAAK,CACd,KAAK,CACJ,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM,EAC3C,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,QAAQ,IAAI,CAAC,IAAI,CAAC,MAAM,EAE7C,OAAO;QACZ;QAEA,OAAO,IAAI,CAAC,IAAI,CACb,KAAK,CAAC,OACN,MAAM,CACL,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,OAAO;IAE3E;IAEA;;;;;;;;;;;;;;;;;;;GAmBC,GACD,OAAO,KAAK,EAAE,WAAW,EAAE,KAAK,EAAE;QAChC,mBAAmB,GACnB,MAAM,QAAQ,eAAe;QAE7B,IAAI,CAAC,SAAS,CAAC,KAAK,KAAK,CAAC;QAC1B,MAAM,UAAU,IAAI,CAAC,KAAK,CAAC,MAAM,CAC/B,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,OACpB,OAAO,iBAAiB;QAE1B,IAAI,OAAO,YAAY,IAAI,CAAC,IAAI,EAAE;QAClC,OAAO,QAAQ,OAAO;IACxB;IAEA;;;;;;;GAOC,GACD,MAAM;QACJ,IAAI,CAAC,SAAS,CAAC,OAAO,iBAAiB;QACvC,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG;IACtB;IAEA;;;;;;;;GAQC,GACD,KAAK,IAAI,EAAE;QACT,IAAI,CAAC,SAAS,CAAC,OAAO,iBAAiB;QACvC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;IACjB;IAEA;;;;;;;;GAQC,GACD,SAAS,KAAK,EAAE;QACd,IAAI,CAAC,SAAS,CAAC,OAAO,iBAAiB;QACvC,YAAY,IAAI,CAAC,IAAI,EAAE;IACzB;IAEA;;;;;;;;GAQC,GACD,QAAQ,IAAI,EAAE;QACZ,IAAI,CAAC,SAAS,CAAC;QACf,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;IAClB;IAEA;;;;;;;;GAQC,GACD,YAAY,KAAK,EAAE;QACjB,IAAI,CAAC,SAAS,CAAC;QACf,YAAY,IAAI,CAAC,KAAK,EAAE,MAAM,OAAO;IACvC;IAEA;;;;;;;;;;;GAWC,GACD,UAAU,CAAC,EAAE;QACX,IACE,MAAM,IAAI,CAAC,IAAI,CAAC,MAAM,IACrB,IAAI,IAAI,CAAC,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,KAAK,KAC9C,IAAI,KAAK,IAAI,CAAC,IAAI,CAAC,MAAM,KAAK,GAE/B;QACF,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YACxB,+BAA+B;YAC/B,MAAM,UAAU,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,GAAG,OAAO,iBAAiB;YAC5D,YAAY,IAAI,CAAC,KAAK,EAAE,QAAQ,OAAO;QACzC,OAAO;YACL,gCAAgC;YAChC,MAAM,UAAU,IAAI,CAAC,KAAK,CAAC,MAAM,CAC/B,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,GACvC,OAAO,iBAAiB;YAE1B,YAAY,IAAI,CAAC,IAAI,EAAE,QAAQ,OAAO;QACxC;IACF;AACF;AAEA;;;;;;;;;;;CAWC,GACD,SAAS,YAAY,IAAI,EAAE,KAAK;IAC9B,mBAAmB,GACnB,IAAI,aAAa;IAEjB,IAAI,MAAM,MAAM,GAAG,kNAAS,CAAC,kBAAkB,EAAE;QAC/C,KAAK,IAAI,IAAI;IACf,OAAO;QACL,MAAO,aAAa,MAAM,MAAM,CAAE;YAChC,KAAK,IAAI,IACJ,MAAM,KAAK,CAAC,YAAY,aAAa,kNAAS,CAAC,kBAAkB;YAEtE,cAAc,kNAAS,CAAC,kBAAkB;QAC5C;IACF;AACF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1870, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark-util-subtokenize/dev/index.js"],"sourcesContent":["/**\n * @import {Chunk, Event, Token} from 'micromark-util-types'\n */\n\nimport {ok as assert} from 'devlop'\nimport {splice} from 'micromark-util-chunked'\nimport {codes, types} from 'micromark-util-symbol'\nimport {SpliceBuffer} from './lib/splice-buffer.js'\n\n// Hidden API exposed for testing.\nexport {SpliceBuffer} from './lib/splice-buffer.js'\n\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} eventsArray\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\n// eslint-disable-next-line complexity\nexport function subtokenize(eventsArray) {\n  /** @type {Record<string, number>} */\n  const jumps = {}\n  let index = -1\n  /** @type {Event} */\n  let event\n  /** @type {number | undefined} */\n  let lineIndex\n  /** @type {number} */\n  let otherIndex\n  /** @type {Event} */\n  let otherEvent\n  /** @type {Array<Event>} */\n  let parameters\n  /** @type {Array<Event>} */\n  let subevents\n  /** @type {boolean | undefined} */\n  let more\n  const events = new SpliceBuffer(eventsArray)\n\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index]\n    }\n\n    event = events.get(index)\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (\n      index &&\n      event[1].type === types.chunkFlow &&\n      events.get(index - 1)[1].type === types.listItemPrefix\n    ) {\n      assert(event[1]._tokenizer, 'expected `_tokenizer` on subtokens')\n      subevents = event[1]._tokenizer.events\n      otherIndex = 0\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === types.lineEndingBlank\n      ) {\n        otherIndex += 2\n      }\n\n      if (\n        otherIndex < subevents.length &&\n        subevents[otherIndex][1].type === types.content\n      ) {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === types.content) {\n            break\n          }\n\n          if (subevents[otherIndex][1].type === types.chunkText) {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true\n            otherIndex++\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index))\n        index = jumps[index]\n        more = true\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index\n      lineIndex = undefined\n\n      while (otherIndex--) {\n        otherEvent = events.get(otherIndex)\n\n        if (\n          otherEvent[1].type === types.lineEnding ||\n          otherEvent[1].type === types.lineEndingBlank\n        ) {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events.get(lineIndex)[1].type = types.lineEndingBlank\n            }\n\n            otherEvent[1].type = types.lineEnding\n            lineIndex = otherIndex\n          }\n        } else if (\n          otherEvent[1].type === types.linePrefix ||\n          otherEvent[1].type === types.listItemIndent\n        ) {\n          // Move past.\n        } else {\n          break\n        }\n      }\n\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = {...events.get(lineIndex)[1].start}\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index)\n        parameters.unshift(event)\n        events.splice(lineIndex, index - lineIndex + 1, parameters)\n      }\n    }\n  }\n\n  // The changes to the `events` buffer must be copied back into the eventsArray\n  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0))\n  return !more\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {SpliceBuffer<Event>} events\n *   Events.\n * @param {number} eventIndex\n *   Index.\n * @returns {Record<string, number>}\n *   Gaps.\n */\nfunction subcontent(events, eventIndex) {\n  const token = events.get(eventIndex)[1]\n  const context = events.get(eventIndex)[2]\n  let startPosition = eventIndex - 1\n  /** @type {Array<number>} */\n  const startPositions = []\n  assert(token.contentType, 'expected `contentType` on subtokens')\n\n  let tokenizer = token._tokenizer\n\n  if (!tokenizer) {\n    tokenizer = context.parser[token.contentType](token.start)\n\n    if (token._contentTypeTextTrailing) {\n      tokenizer._contentTypeTextTrailing = true\n    }\n  }\n\n  const childEvents = tokenizer.events\n  /** @type {Array<[number, number]>} */\n  const jumps = []\n  /** @type {Record<string, number>} */\n  const gaps = {}\n  /** @type {Array<Chunk>} */\n  let stream\n  /** @type {Token | undefined} */\n  let previous\n  let index = -1\n  /** @type {Token | undefined} */\n  let current = token\n  let adjust = 0\n  let start = 0\n  const breaks = [start]\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events.get(++startPosition)[1] !== current) {\n      // Empty.\n    }\n\n    assert(\n      !previous || current.previous === previous,\n      'expected previous to match'\n    )\n    assert(!previous || previous.next === current, 'expected next to match')\n\n    startPositions.push(startPosition)\n\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current)\n\n      if (!current.next) {\n        stream.push(codes.eof)\n      }\n\n      if (previous) {\n        tokenizer.defineSkip(current.start)\n      }\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true\n      }\n\n      tokenizer.write(stream)\n\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined\n      }\n    }\n\n    // Unravel the next token.\n    previous = current\n    current = current.next\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token\n\n  while (++index < childEvents.length) {\n    if (\n      // Find a void token that includes a break.\n      childEvents[index][0] === 'exit' &&\n      childEvents[index - 1][0] === 'enter' &&\n      childEvents[index][1].type === childEvents[index - 1][1].type &&\n      childEvents[index][1].start.line !== childEvents[index][1].end.line\n    ) {\n      assert(current, 'expected a current token')\n      start = index + 1\n      breaks.push(start)\n      // Help GC.\n      current._tokenizer = undefined\n      current.previous = undefined\n      current = current.next\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = []\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined\n    current.previous = undefined\n    assert(!current.next, 'expected no next token')\n  } else {\n    breaks.pop()\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length\n\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1])\n    const start = startPositions.pop()\n    assert(start !== undefined, 'expected a start position when splicing')\n    jumps.push([start, start + slice.length - 1])\n    events.splice(start, 2, slice)\n  }\n\n  jumps.reverse()\n  index = -1\n\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1]\n    adjust += jumps[index][1] - jumps[index][0] - 1\n  }\n\n  return gaps\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;AAED;AACA;AACA;AAAA;AACA;;;;;;AAcO,SAAS,YAAY,WAAW;IACrC,mCAAmC,GACnC,MAAM,QAAQ,CAAC;IACf,IAAI,QAAQ,CAAC;IACb,kBAAkB,GAClB,IAAI;IACJ,+BAA+B,GAC/B,IAAI;IACJ,mBAAmB,GACnB,IAAI;IACJ,kBAAkB,GAClB,IAAI;IACJ,yBAAyB,GACzB,IAAI;IACJ,yBAAyB,GACzB,IAAI;IACJ,gCAAgC,GAChC,IAAI;IACJ,MAAM,SAAS,IAAI,6RAAY,CAAC;IAEhC,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;QAC9B,MAAO,SAAS,MAAO;YACrB,QAAQ,KAAK,CAAC,MAAM;QACtB;QAEA,QAAQ,OAAO,GAAG,CAAC;QAEnB,yEAAyE;QACzE,0CAA0C;QAC1C,IACE,SACA,KAAK,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,SAAS,IACjC,OAAO,GAAG,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,cAAc,EACtD;YACA,IAAA,wLAAM,EAAC,KAAK,CAAC,EAAE,CAAC,UAAU,EAAE;YAC5B,YAAY,KAAK,CAAC,EAAE,CAAC,UAAU,CAAC,MAAM;YACtC,aAAa;YAEb,IACE,aAAa,UAAU,MAAM,IAC7B,SAAS,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,eAAe,EACvD;gBACA,cAAc;YAChB;YAEA,IACE,aAAa,UAAU,MAAM,IAC7B,SAAS,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,OAAO,EAC/C;gBACA,MAAO,EAAE,aAAa,UAAU,MAAM,CAAE;oBACtC,IAAI,SAAS,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,OAAO,EAAE;wBACnD;oBACF;oBAEA,IAAI,SAAS,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,SAAS,EAAE;wBACrD,SAAS,CAAC,WAAW,CAAC,EAAE,CAAC,2BAA2B,GAAG;wBACvD;oBACF;gBACF;YACF;QACF;QAEA,SAAS;QACT,IAAI,KAAK,CAAC,EAAE,KAAK,SAAS;YACxB,IAAI,KAAK,CAAC,EAAE,CAAC,WAAW,EAAE;gBACxB,OAAO,MAAM,CAAC,OAAO,WAAW,QAAQ;gBACxC,QAAQ,KAAK,CAAC,MAAM;gBACpB,OAAO;YACT;QACF,OAEK,IAAI,KAAK,CAAC,EAAE,CAAC,UAAU,EAAE;YAC5B,aAAa;YACb,YAAY;YAEZ,MAAO,aAAc;gBACnB,aAAa,OAAO,GAAG,CAAC;gBAExB,IACE,UAAU,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,UAAU,IACvC,UAAU,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,eAAe,EAC5C;oBACA,IAAI,UAAU,CAAC,EAAE,KAAK,SAAS;wBAC7B,IAAI,WAAW;4BACb,OAAO,GAAG,CAAC,UAAU,CAAC,EAAE,CAAC,IAAI,GAAG,0MAAK,CAAC,eAAe;wBACvD;wBAEA,UAAU,CAAC,EAAE,CAAC,IAAI,GAAG,0MAAK,CAAC,UAAU;wBACrC,YAAY;oBACd;gBACF,OAAO,IACL,UAAU,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,UAAU,IACvC,UAAU,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,cAAc,EAC3C;gBACA,aAAa;gBACf,OAAO;oBACL;gBACF;YACF;YAEA,IAAI,WAAW;gBACb,gBAAgB;gBAChB,KAAK,CAAC,EAAE,CAAC,GAAG,GAAG;oBAAC,GAAG,OAAO,GAAG,CAAC,UAAU,CAAC,EAAE,CAAC,KAAK;gBAAA;gBAEjD,yCAAyC;gBACzC,aAAa,OAAO,KAAK,CAAC,WAAW;gBACrC,WAAW,OAAO,CAAC;gBACnB,OAAO,MAAM,CAAC,WAAW,QAAQ,YAAY,GAAG;YAClD;QACF;IACF;IAEA,8EAA8E;IAC9E,IAAA,4MAAM,EAAC,aAAa,GAAG,OAAO,iBAAiB,EAAE,OAAO,KAAK,CAAC;IAC9D,OAAO,CAAC;AACV;AAEA;;;;;;;;;CASC,GACD,SAAS,WAAW,MAAM,EAAE,UAAU;IACpC,MAAM,QAAQ,OAAO,GAAG,CAAC,WAAW,CAAC,EAAE;IACvC,MAAM,UAAU,OAAO,GAAG,CAAC,WAAW,CAAC,EAAE;IACzC,IAAI,gBAAgB,aAAa;IACjC,0BAA0B,GAC1B,MAAM,iBAAiB,EAAE;IACzB,IAAA,wLAAM,EAAC,MAAM,WAAW,EAAE;IAE1B,IAAI,YAAY,MAAM,UAAU;IAEhC,IAAI,CAAC,WAAW;QACd,YAAY,QAAQ,MAAM,CAAC,MAAM,WAAW,CAAC,CAAC,MAAM,KAAK;QAEzD,IAAI,MAAM,wBAAwB,EAAE;YAClC,UAAU,wBAAwB,GAAG;QACvC;IACF;IAEA,MAAM,cAAc,UAAU,MAAM;IACpC,oCAAoC,GACpC,MAAM,QAAQ,EAAE;IAChB,mCAAmC,GACnC,MAAM,OAAO,CAAC;IACd,yBAAyB,GACzB,IAAI;IACJ,8BAA8B,GAC9B,IAAI;IACJ,IAAI,QAAQ,CAAC;IACb,8BAA8B,GAC9B,IAAI,UAAU;IACd,IAAI,SAAS;IACb,IAAI,QAAQ;IACZ,MAAM,SAAS;QAAC;KAAM;IAEtB,sEAAsE;IACtE,gBAAgB;IAChB,MAAO,QAAS;QACd,iDAAiD;QACjD,MAAO,OAAO,GAAG,CAAC,EAAE,cAAc,CAAC,EAAE,KAAK,QAAS;QACjD,SAAS;QACX;QAEA,IAAA,wLAAM,EACJ,CAAC,YAAY,QAAQ,QAAQ,KAAK,UAClC;QAEF,IAAA,wLAAM,EAAC,CAAC,YAAY,SAAS,IAAI,KAAK,SAAS;QAE/C,eAAe,IAAI,CAAC;QAEpB,IAAI,CAAC,QAAQ,UAAU,EAAE;YACvB,SAAS,QAAQ,WAAW,CAAC;YAE7B,IAAI,CAAC,QAAQ,IAAI,EAAE;gBACjB,OAAO,IAAI,CAAC,0MAAK,CAAC,GAAG;YACvB;YAEA,IAAI,UAAU;gBACZ,UAAU,UAAU,CAAC,QAAQ,KAAK;YACpC;YAEA,IAAI,QAAQ,2BAA2B,EAAE;gBACvC,UAAU,kCAAkC,GAAG;YACjD;YAEA,UAAU,KAAK,CAAC;YAEhB,IAAI,QAAQ,2BAA2B,EAAE;gBACvC,UAAU,kCAAkC,GAAG;YACjD;QACF;QAEA,0BAA0B;QAC1B,WAAW;QACX,UAAU,QAAQ,IAAI;IACxB;IAEA,6EAA6E;IAC7E,sBAAsB;IACtB,UAAU;IAEV,MAAO,EAAE,QAAQ,YAAY,MAAM,CAAE;QACnC,IACE,2CAA2C;QAC3C,WAAW,CAAC,MAAM,CAAC,EAAE,KAAK,UAC1B,WAAW,CAAC,QAAQ,EAAE,CAAC,EAAE,KAAK,WAC9B,WAAW,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,WAAW,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,IAAI,IAC7D,WAAW,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,IAAI,KAAK,WAAW,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,CAAC,IAAI,EACnE;YACA,IAAA,wLAAM,EAAC,SAAS;YAChB,QAAQ,QAAQ;YAChB,OAAO,IAAI,CAAC;YACZ,WAAW;YACX,QAAQ,UAAU,GAAG;YACrB,QAAQ,QAAQ,GAAG;YACnB,UAAU,QAAQ,IAAI;QACxB;IACF;IAEA,WAAW;IACX,UAAU,MAAM,GAAG,EAAE;IAErB,yEAAyE;IACzE,2DAA2D;IAC3D,sEAAsE;IACtE,IAAI,SAAS;QACX,WAAW;QACX,QAAQ,UAAU,GAAG;QACrB,QAAQ,QAAQ,GAAG;QACnB,IAAA,wLAAM,EAAC,CAAC,QAAQ,IAAI,EAAE;IACxB,OAAO;QACL,OAAO,GAAG;IACZ;IAEA,uEAAuE;IACvE,+DAA+D;IAC/D,QAAQ,OAAO,MAAM;IAErB,MAAO,QAAS;QACd,MAAM,QAAQ,YAAY,KAAK,CAAC,MAAM,CAAC,MAAM,EAAE,MAAM,CAAC,QAAQ,EAAE;QAChE,MAAM,QAAQ,eAAe,GAAG;QAChC,IAAA,wLAAM,EAAC,UAAU,WAAW;QAC5B,MAAM,IAAI,CAAC;YAAC;YAAO,QAAQ,MAAM,MAAM,GAAG;SAAE;QAC5C,OAAO,MAAM,CAAC,OAAO,GAAG;IAC1B;IAEA,MAAM,OAAO;IACb,QAAQ,CAAC;IAET,MAAO,EAAE,QAAQ,MAAM,MAAM,CAAE;QAC7B,IAAI,CAAC,SAAS,KAAK,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,SAAS,KAAK,CAAC,MAAM,CAAC,EAAE;QACzD,UAAU,KAAK,CAAC,MAAM,CAAC,EAAE,GAAG,KAAK,CAAC,MAAM,CAAC,EAAE,GAAG;IAChD;IAEA,OAAO;AACT","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2082, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/node_modules/micromark-util-decode-numeric-character-reference/dev/index.js"],"sourcesContent":["import {codes, values} from 'micromark-util-symbol'\n\n/**\n * Turn the number (in string form as either hexa- or plain decimal) coming from\n * a numeric character reference into a character.\n *\n * Sort of like `String.fromCodePoint(Number.parseInt(value, base))`, but makes\n * non-characters and control characters safe.\n *\n * @param {string} value\n *   Value to decode.\n * @param {number} base\n *   Numeric base.\n * @returns {string}\n *   Character.\n */\nexport function decodeNumericCharacterReference(value, base) {\n  const code = Number.parseInt(value, base)\n\n  if (\n    // C0 except for HT, LF, FF, CR, space.\n    code < codes.ht ||\n    code === codes.vt ||\n    (code > codes.cr && code < codes.space) ||\n    // Control character (DEL) of C0, and C1 controls.\n    (code > codes.tilde && code < 160) ||\n    // Lone high surrogates and low surrogates.\n    (code > 55_295 && code < 57_344) ||\n    // Noncharacters.\n    (code > 64_975 && code < 65_008) ||\n    /* eslint-disable no-bitwise */\n    (code & 65_535) === 65_535 ||\n    (code & 65_535) === 65_534 ||\n    /* eslint-enable no-bitwise */\n    // Out of range\n    code > 1_114_111\n  ) {\n    return values.replacementCharacter\n  }\n\n  return String.fromCodePoint(code)\n}\n"],"names":[],"mappings":";;;;AAAA;AAAA;;AAgBO,SAAS,gCAAgC,KAAK,EAAE,IAAI;IACzD,MAAM,OAAO,OAAO,QAAQ,CAAC,OAAO;IAEpC,IACE,uCAAuC;IACvC,OAAO,0MAAK,CAAC,EAAE,IACf,SAAS,0MAAK,CAAC,EAAE,IAChB,OAAO,0MAAK,CAAC,EAAE,IAAI,OAAO,0MAAK,CAAC,KAAK,IAErC,OAAO,0MAAK,CAAC,KAAK,IAAI,OAAO,OAE7B,OAAO,UAAU,OAAO,UAExB,OAAO,UAAU,OAAO,UACzB,6BAA6B,GAC7B,CAAC,OAAO,MAAM,MAAM,UACpB,CAAC,OAAO,MAAM,MAAM,UACpB,4BAA4B,GAC5B,eAAe;IACf,OAAO,WACP;QACA,OAAO,4MAAM,CAAC,oBAAoB;IACpC;IAEA,OAAO,OAAO,aAAa,CAAC;AAC9B","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2102, "column": 0}, "map": {"version":3,"sources":["file:///Users/air13/code/cogni/cogni-frontend/node_modules/mdast-util-from-markdown/dev/lib/index.js"],"sourcesContent":["/**\n * @import {\n *   Break,\n *   Blockquote,\n *   Code,\n *   Definition,\n *   Emphasis,\n *   Heading,\n *   Html,\n *   Image,\n *   InlineCode,\n *   Link,\n *   ListItem,\n *   List,\n *   Nodes,\n *   Paragraph,\n *   PhrasingContent,\n *   ReferenceType,\n *   Root,\n *   Strong,\n *   Text,\n *   ThematicBreak\n * } from 'mdast'\n * @import {\n *   Encoding,\n *   Event,\n *   Token,\n *   Value\n * } from 'micromark-util-types'\n * @import {Point} from 'unist'\n * @import {\n *   CompileContext,\n *   CompileData,\n *   Config,\n *   Extension,\n *   Handle,\n *   OnEnterError,\n *   Options\n * } from './types.js'\n */\n\nimport {ok as assert} from 'devlop'\nimport {toString} from 'mdast-util-to-string'\nimport {parse, postprocess, preprocess} from 'micromark'\nimport {decodeNumericCharacterReference} from 'micromark-util-decode-numeric-character-reference'\nimport {decodeString} from 'micromark-util-decode-string'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\nimport {codes, constants, types} from 'micromark-util-symbol'\nimport {decodeNamedCharacterReference} from 'decode-named-character-reference'\nimport {stringifyPosition} from 'unist-util-stringify-position'\n\nconst own = {}.hasOwnProperty\n\n/**\n * Turn markdown into a syntax tree.\n *\n * @overload\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {Options | null | undefined} [options]\n * @returns {Root}\n *\n * @overload\n * @param {Value} value\n * @param {Options | null | undefined} [options]\n * @returns {Root}\n *\n * @param {Value} value\n *   Markdown to parse.\n * @param {Encoding | Options | null | undefined} [encoding]\n *   Character encoding for when `value` is `Buffer`.\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {Root}\n *   mdast tree.\n */\nexport function fromMarkdown(value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding\n    encoding = undefined\n  }\n\n  return compiler(options)(\n    postprocess(\n      parse(options)\n        .document()\n        .write(preprocess()(value, encoding, true))\n    )\n  )\n}\n\n/**\n * Note this compiler only understand complete buffering, not streaming.\n *\n * @param {Options | null | undefined} [options]\n */\nfunction compiler(options) {\n  /** @type {Config} */\n  const config = {\n    transforms: [],\n    canContainEols: ['emphasis', 'fragment', 'heading', 'paragraph', 'strong'],\n    enter: {\n      autolink: opener(link),\n      autolinkProtocol: onenterdata,\n      autolinkEmail: onenterdata,\n      atxHeading: opener(heading),\n      blockQuote: opener(blockQuote),\n      characterEscape: onenterdata,\n      characterReference: onenterdata,\n      codeFenced: opener(codeFlow),\n      codeFencedFenceInfo: buffer,\n      codeFencedFenceMeta: buffer,\n      codeIndented: opener(codeFlow, buffer),\n      codeText: opener(codeText, buffer),\n      codeTextData: onenterdata,\n      data: onenterdata,\n      codeFlowValue: onenterdata,\n      definition: opener(definition),\n      definitionDestinationString: buffer,\n      definitionLabelString: buffer,\n      definitionTitleString: buffer,\n      emphasis: opener(emphasis),\n      hardBreakEscape: opener(hardBreak),\n      hardBreakTrailing: opener(hardBreak),\n      htmlFlow: opener(html, buffer),\n      htmlFlowData: onenterdata,\n      htmlText: opener(html, buffer),\n      htmlTextData: onenterdata,\n      image: opener(image),\n      label: buffer,\n      link: opener(link),\n      listItem: opener(listItem),\n      listItemValue: onenterlistitemvalue,\n      listOrdered: opener(list, onenterlistordered),\n      listUnordered: opener(list),\n      paragraph: opener(paragraph),\n      reference: onenterreference,\n      referenceString: buffer,\n      resourceDestinationString: buffer,\n      resourceTitleString: buffer,\n      setextHeading: opener(heading),\n      strong: opener(strong),\n      thematicBreak: opener(thematicBreak)\n    },\n    exit: {\n      atxHeading: closer(),\n      atxHeadingSequence: onexitatxheadingsequence,\n      autolink: closer(),\n      autolinkEmail: onexitautolinkemail,\n      autolinkProtocol: onexitautolinkprotocol,\n      blockQuote: closer(),\n      characterEscapeValue: onexitdata,\n      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n      characterReferenceValue: onexitcharacterreferencevalue,\n      characterReference: onexitcharacterreference,\n      codeFenced: closer(onexitcodefenced),\n      codeFencedFence: onexitcodefencedfence,\n      codeFencedFenceInfo: onexitcodefencedfenceinfo,\n      codeFencedFenceMeta: onexitcodefencedfencemeta,\n      codeFlowValue: onexitdata,\n      codeIndented: closer(onexitcodeindented),\n      codeText: closer(onexitcodetext),\n      codeTextData: onexitdata,\n      data: onexitdata,\n      definition: closer(),\n      definitionDestinationString: onexitdefinitiondestinationstring,\n      definitionLabelString: onexitdefinitionlabelstring,\n      definitionTitleString: onexitdefinitiontitlestring,\n      emphasis: closer(),\n      hardBreakEscape: closer(onexithardbreak),\n      hardBreakTrailing: closer(onexithardbreak),\n      htmlFlow: closer(onexithtmlflow),\n      htmlFlowData: onexitdata,\n      htmlText: closer(onexithtmltext),\n      htmlTextData: onexitdata,\n      image: closer(onexitimage),\n      label: onexitlabel,\n      labelText: onexitlabeltext,\n      lineEnding: onexitlineending,\n      link: closer(onexitlink),\n      listItem: closer(),\n      listOrdered: closer(),\n      listUnordered: closer(),\n      paragraph: closer(),\n      referenceString: onexitreferencestring,\n      resourceDestinationString: onexitresourcedestinationstring,\n      resourceTitleString: onexitresourcetitlestring,\n      resource: onexitresource,\n      setextHeading: closer(onexitsetextheading),\n      setextHeadingLineSequence: onexitsetextheadinglinesequence,\n      setextHeadingText: onexitsetextheadingtext,\n      strong: closer(),\n      thematicBreak: closer()\n    }\n  }\n\n  configure(config, (options || {}).mdastExtensions || [])\n\n  /** @type {CompileData} */\n  const data = {}\n\n  return compile\n\n  /**\n   * Turn micromark events into an mdast tree.\n   *\n   * @param {Array<Event>} events\n   *   Events.\n   * @returns {Root}\n   *   mdast tree.\n   */\n  function compile(events) {\n    /** @type {Root} */\n    let tree = {type: 'root', children: []}\n    /** @type {Omit<CompileContext, 'sliceSerialize'>} */\n    const context = {\n      stack: [tree],\n      tokenStack: [],\n      config,\n      enter,\n      exit,\n      buffer,\n      resume,\n      data\n    }\n    /** @type {Array<number>} */\n    const listStack = []\n    let index = -1\n\n    while (++index < events.length) {\n      // We preprocess lists to add `listItem` tokens, and to infer whether\n      // items the list itself are spread out.\n      if (\n        events[index][1].type === types.listOrdered ||\n        events[index][1].type === types.listUnordered\n      ) {\n        if (events[index][0] === 'enter') {\n          listStack.push(index)\n        } else {\n          const tail = listStack.pop()\n          assert(typeof tail === 'number', 'expected list ot be open')\n          index = prepareList(events, tail, index)\n        }\n      }\n    }\n\n    index = -1\n\n    while (++index < events.length) {\n      const handler = config[events[index][0]]\n\n      if (own.call(handler, events[index][1].type)) {\n        handler[events[index][1].type].call(\n          Object.assign(\n            {sliceSerialize: events[index][2].sliceSerialize},\n            context\n          ),\n          events[index][1]\n        )\n      }\n    }\n\n    // Handle tokens still being open.\n    if (context.tokenStack.length > 0) {\n      const tail = context.tokenStack[context.tokenStack.length - 1]\n      const handler = tail[1] || defaultOnError\n      handler.call(context, undefined, tail[0])\n    }\n\n    // Figure out `root` position.\n    tree.position = {\n      start: point(\n        events.length > 0 ? events[0][1].start : {line: 1, column: 1, offset: 0}\n      ),\n      end: point(\n        events.length > 0\n          ? events[events.length - 2][1].end\n          : {line: 1, column: 1, offset: 0}\n      )\n    }\n\n    // Call transforms.\n    index = -1\n    while (++index < config.transforms.length) {\n      tree = config.transforms[index](tree) || tree\n    }\n\n    return tree\n  }\n\n  /**\n   * @param {Array<Event>} events\n   * @param {number} start\n   * @param {number} length\n   * @returns {number}\n   */\n  function prepareList(events, start, length) {\n    let index = start - 1\n    let containerBalance = -1\n    let listSpread = false\n    /** @type {Token | undefined} */\n    let listItem\n    /** @type {number | undefined} */\n    let lineIndex\n    /** @type {number | undefined} */\n    let firstBlankLineIndex\n    /** @type {boolean | undefined} */\n    let atMarker\n\n    while (++index <= length) {\n      const event = events[index]\n\n      switch (event[1].type) {\n        case types.listUnordered:\n        case types.listOrdered:\n        case types.blockQuote: {\n          if (event[0] === 'enter') {\n            containerBalance++\n          } else {\n            containerBalance--\n          }\n\n          atMarker = undefined\n\n          break\n        }\n\n        case types.lineEndingBlank: {\n          if (event[0] === 'enter') {\n            if (\n              listItem &&\n              !atMarker &&\n              !containerBalance &&\n              !firstBlankLineIndex\n            ) {\n              firstBlankLineIndex = index\n            }\n\n            atMarker = undefined\n          }\n\n          break\n        }\n\n        case types.linePrefix:\n        case types.listItemValue:\n        case types.listItemMarker:\n        case types.listItemPrefix:\n        case types.listItemPrefixWhitespace: {\n          // Empty.\n\n          break\n        }\n\n        default: {\n          atMarker = undefined\n        }\n      }\n\n      if (\n        (!containerBalance &&\n          event[0] === 'enter' &&\n          event[1].type === types.listItemPrefix) ||\n        (containerBalance === -1 &&\n          event[0] === 'exit' &&\n          (event[1].type === types.listUnordered ||\n            event[1].type === types.listOrdered))\n      ) {\n        if (listItem) {\n          let tailIndex = index\n          lineIndex = undefined\n\n          while (tailIndex--) {\n            const tailEvent = events[tailIndex]\n\n            if (\n              tailEvent[1].type === types.lineEnding ||\n              tailEvent[1].type === types.lineEndingBlank\n            ) {\n              if (tailEvent[0] === 'exit') continue\n\n              if (lineIndex) {\n                events[lineIndex][1].type = types.lineEndingBlank\n                listSpread = true\n              }\n\n              tailEvent[1].type = types.lineEnding\n              lineIndex = tailIndex\n            } else if (\n              tailEvent[1].type === types.linePrefix ||\n              tailEvent[1].type === types.blockQuotePrefix ||\n              tailEvent[1].type === types.blockQuotePrefixWhitespace ||\n              tailEvent[1].type === types.blockQuoteMarker ||\n              tailEvent[1].type === types.listItemIndent\n            ) {\n              // Empty\n            } else {\n              break\n            }\n          }\n\n          if (\n            firstBlankLineIndex &&\n            (!lineIndex || firstBlankLineIndex < lineIndex)\n          ) {\n            listItem._spread = true\n          }\n\n          // Fix position.\n          listItem.end = Object.assign(\n            {},\n            lineIndex ? events[lineIndex][1].start : event[1].end\n          )\n\n          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]])\n          index++\n          length++\n        }\n\n        // Create a new list item.\n        if (event[1].type === types.listItemPrefix) {\n          /** @type {Token} */\n          const item = {\n            type: 'listItem',\n            _spread: false,\n            start: Object.assign({}, event[1].start),\n            // @ts-expect-error: we’ll add `end` in a second.\n            end: undefined\n          }\n          listItem = item\n          events.splice(index, 0, ['enter', item, event[2]])\n          index++\n          length++\n          firstBlankLineIndex = undefined\n          atMarker = true\n        }\n      }\n    }\n\n    events[start][1]._spread = listSpread\n    return length\n  }\n\n  /**\n   * Create an opener handle.\n   *\n   * @param {(token: Token) => Nodes} create\n   *   Create a node.\n   * @param {Handle | undefined} [and]\n   *   Optional function to also run.\n   * @returns {Handle}\n   *   Handle.\n   */\n  function opener(create, and) {\n    return open\n\n    /**\n     * @this {CompileContext}\n     * @param {Token} token\n     * @returns {undefined}\n     */\n    function open(token) {\n      enter.call(this, create(token), token)\n      if (and) and.call(this, token)\n    }\n  }\n\n  /**\n   * @type {CompileContext['buffer']}\n   */\n  function buffer() {\n    this.stack.push({type: 'fragment', children: []})\n  }\n\n  /**\n   * @type {CompileContext['enter']}\n   */\n  function enter(node, token, errorHandler) {\n    const parent = this.stack[this.stack.length - 1]\n    assert(parent, 'expected `parent`')\n    assert('children' in parent, 'expected `parent`')\n    /** @type {Array<Nodes>} */\n    const siblings = parent.children\n    siblings.push(node)\n    this.stack.push(node)\n    this.tokenStack.push([token, errorHandler || undefined])\n    node.position = {\n      start: point(token.start),\n      // @ts-expect-error: `end` will be patched later.\n      end: undefined\n    }\n  }\n\n  /**\n   * Create a closer handle.\n   *\n   * @param {Handle | undefined} [and]\n   *   Optional function to also run.\n   * @returns {Handle}\n   *   Handle.\n   */\n  function closer(and) {\n    return close\n\n    /**\n     * @this {CompileContext}\n     * @param {Token} token\n     * @returns {undefined}\n     */\n    function close(token) {\n      if (and) and.call(this, token)\n      exit.call(this, token)\n    }\n  }\n\n  /**\n   * @type {CompileContext['exit']}\n   */\n  function exit(token, onExitError) {\n    const node = this.stack.pop()\n    assert(node, 'expected `node`')\n    const open = this.tokenStack.pop()\n\n    if (!open) {\n      throw new Error(\n        'Cannot close `' +\n          token.type +\n          '` (' +\n          stringifyPosition({start: token.start, end: token.end}) +\n          '): it’s not open'\n      )\n    } else if (open[0].type !== token.type) {\n      if (onExitError) {\n        onExitError.call(this, token, open[0])\n      } else {\n        const handler = open[1] || defaultOnError\n        handler.call(this, token, open[0])\n      }\n    }\n\n    assert(node.type !== 'fragment', 'unexpected fragment `exit`ed')\n    assert(node.position, 'expected `position` to be defined')\n    node.position.end = point(token.end)\n  }\n\n  /**\n   * @type {CompileContext['resume']}\n   */\n  function resume() {\n    return toString(this.stack.pop())\n  }\n\n  //\n  // Handlers.\n  //\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistordered() {\n    this.data.expectingFirstListItemValue = true\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistitemvalue(token) {\n    if (this.data.expectingFirstListItemValue) {\n      const ancestor = this.stack[this.stack.length - 2]\n      assert(ancestor, 'expected nodes on stack')\n      assert(ancestor.type === 'list', 'expected list on stack')\n      ancestor.start = Number.parseInt(\n        this.sliceSerialize(token),\n        constants.numericBaseDecimal\n      )\n      this.data.expectingFirstListItemValue = undefined\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfenceinfo() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'code', 'expected code on stack')\n    node.lang = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfencemeta() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'code', 'expected code on stack')\n    node.meta = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfence() {\n    // Exit if this is the closing fence.\n    if (this.data.flowCodeInside) return\n    this.buffer()\n    this.data.flowCodeInside = true\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefenced() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'code', 'expected code on stack')\n\n    node.value = data.replace(/^(\\r?\\n|\\r)|(\\r?\\n|\\r)$/g, '')\n    this.data.flowCodeInside = undefined\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodeindented() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'code', 'expected code on stack')\n\n    node.value = data.replace(/(\\r?\\n|\\r)$/g, '')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitionlabelstring(token) {\n    const label = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'definition', 'expected definition on stack')\n\n    node.label = label\n    node.identifier = normalizeIdentifier(\n      this.sliceSerialize(token)\n    ).toLowerCase()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiontitlestring() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'definition', 'expected definition on stack')\n\n    node.title = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiondestinationstring() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'definition', 'expected definition on stack')\n\n    node.url = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheadingsequence(token) {\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'heading', 'expected heading on stack')\n\n    if (!node.depth) {\n      const depth = this.sliceSerialize(token).length\n\n      assert(\n        depth === 1 ||\n          depth === 2 ||\n          depth === 3 ||\n          depth === 4 ||\n          depth === 5 ||\n          depth === 6,\n        'expected `depth` between `1` and `6`'\n      )\n\n      node.depth = depth\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadingtext() {\n    this.data.setextHeadingSlurpLineEnding = true\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadinglinesequence(token) {\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'heading', 'expected heading on stack')\n\n    node.depth =\n      this.sliceSerialize(token).codePointAt(0) === codes.equalsTo ? 1 : 2\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheading() {\n    this.data.setextHeadingSlurpLineEnding = undefined\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onenterdata(token) {\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert('children' in node, 'expected parent on stack')\n    /** @type {Array<Nodes>} */\n    const siblings = node.children\n\n    let tail = siblings[siblings.length - 1]\n\n    if (!tail || tail.type !== 'text') {\n      // Add a new text node.\n      tail = text()\n      tail.position = {\n        start: point(token.start),\n        // @ts-expect-error: we’ll add `end` later.\n        end: undefined\n      }\n      siblings.push(tail)\n    }\n\n    this.stack.push(tail)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitdata(token) {\n    const tail = this.stack.pop()\n    assert(tail, 'expected a `node` to be on the stack')\n    assert('value' in tail, 'expected a `literal` to be on the stack')\n    assert(tail.position, 'expected `node` to have an open position')\n    tail.value += this.sliceSerialize(token)\n    tail.position.end = point(token.end)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlineending(token) {\n    const context = this.stack[this.stack.length - 1]\n    assert(context, 'expected `node`')\n\n    // If we’re at a hard break, include the line ending in there.\n    if (this.data.atHardBreak) {\n      assert('children' in context, 'expected `parent`')\n      const tail = context.children[context.children.length - 1]\n      assert(tail.position, 'expected tail to have a starting position')\n      tail.position.end = point(token.end)\n      this.data.atHardBreak = undefined\n      return\n    }\n\n    if (\n      !this.data.setextHeadingSlurpLineEnding &&\n      config.canContainEols.includes(context.type)\n    ) {\n      onenterdata.call(this, token)\n      onexitdata.call(this, token)\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithardbreak() {\n    this.data.atHardBreak = true\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithtmlflow() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'html', 'expected html on stack')\n\n    node.value = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexithtmltext() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'html', 'expected html on stack')\n\n    node.value = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitcodetext() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'inlineCode', 'expected inline code on stack')\n\n    node.value = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlink() {\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'link', 'expected link on stack')\n\n    // Note: there are also `identifier` and `label` fields on this link node!\n    // These are used / cleaned here.\n\n    // To do: clean.\n    if (this.data.inReference) {\n      /** @type {ReferenceType} */\n      const referenceType = this.data.referenceType || 'shortcut'\n\n      node.type += 'Reference'\n      // @ts-expect-error: mutate.\n      node.referenceType = referenceType\n      // @ts-expect-error: mutate.\n      delete node.url\n      delete node.title\n    } else {\n      // @ts-expect-error: mutate.\n      delete node.identifier\n      // @ts-expect-error: mutate.\n      delete node.label\n    }\n\n    this.data.referenceType = undefined\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitimage() {\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'image', 'expected image on stack')\n\n    // Note: there are also `identifier` and `label` fields on this link node!\n    // These are used / cleaned here.\n\n    // To do: clean.\n    if (this.data.inReference) {\n      /** @type {ReferenceType} */\n      const referenceType = this.data.referenceType || 'shortcut'\n\n      node.type += 'Reference'\n      // @ts-expect-error: mutate.\n      node.referenceType = referenceType\n      // @ts-expect-error: mutate.\n      delete node.url\n      delete node.title\n    } else {\n      // @ts-expect-error: mutate.\n      delete node.identifier\n      // @ts-expect-error: mutate.\n      delete node.label\n    }\n\n    this.data.referenceType = undefined\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlabeltext(token) {\n    const string = this.sliceSerialize(token)\n    const ancestor = this.stack[this.stack.length - 2]\n    assert(ancestor, 'expected ancestor on stack')\n    assert(\n      ancestor.type === 'image' || ancestor.type === 'link',\n      'expected image or link on stack'\n    )\n\n    // @ts-expect-error: stash this on the node, as it might become a reference\n    // later.\n    ancestor.label = decodeString(string)\n    // @ts-expect-error: same as above.\n    ancestor.identifier = normalizeIdentifier(string).toLowerCase()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitlabel() {\n    const fragment = this.stack[this.stack.length - 1]\n    assert(fragment, 'expected node on stack')\n    assert(fragment.type === 'fragment', 'expected fragment on stack')\n    const value = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(\n      node.type === 'image' || node.type === 'link',\n      'expected image or link on stack'\n    )\n\n    // Assume a reference.\n    this.data.inReference = true\n\n    if (node.type === 'link') {\n      /** @type {Array<PhrasingContent>} */\n      const children = fragment.children\n\n      node.children = children\n    } else {\n      node.alt = value\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresourcedestinationstring() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(\n      node.type === 'image' || node.type === 'link',\n      'expected image or link on stack'\n    )\n    node.url = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresourcetitlestring() {\n    const data = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(\n      node.type === 'image' || node.type === 'link',\n      'expected image or link on stack'\n    )\n    node.title = data\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitresource() {\n    this.data.inReference = undefined\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onenterreference() {\n    this.data.referenceType = 'collapsed'\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitreferencestring(token) {\n    const label = this.resume()\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(\n      node.type === 'image' || node.type === 'link',\n      'expected image reference or link reference on stack'\n    )\n\n    // @ts-expect-error: stash this on the node, as it might become a reference\n    // later.\n    node.label = label\n    // @ts-expect-error: same as above.\n    node.identifier = normalizeIdentifier(\n      this.sliceSerialize(token)\n    ).toLowerCase()\n    this.data.referenceType = 'full'\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n\n  function onexitcharacterreferencemarker(token) {\n    assert(\n      token.type === 'characterReferenceMarkerNumeric' ||\n        token.type === 'characterReferenceMarkerHexadecimal'\n    )\n    this.data.characterReferenceType = token.type\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreferencevalue(token) {\n    const data = this.sliceSerialize(token)\n    const type = this.data.characterReferenceType\n    /** @type {string} */\n    let value\n\n    if (type) {\n      value = decodeNumericCharacterReference(\n        data,\n        type === types.characterReferenceMarkerNumeric\n          ? constants.numericBaseDecimal\n          : constants.numericBaseHexadecimal\n      )\n      this.data.characterReferenceType = undefined\n    } else {\n      const result = decodeNamedCharacterReference(data)\n      assert(result !== false, 'expected reference to decode')\n      value = result\n    }\n\n    const tail = this.stack[this.stack.length - 1]\n    assert(tail, 'expected `node`')\n    assert('value' in tail, 'expected `node.value`')\n    tail.value += value\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreference(token) {\n    const tail = this.stack.pop()\n    assert(tail, 'expected `node`')\n    assert(tail.position, 'expected `node.position`')\n    tail.position.end = point(token.end)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkprotocol(token) {\n    onexitdata.call(this, token)\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'link', 'expected link on stack')\n\n    node.url = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkemail(token) {\n    onexitdata.call(this, token)\n    const node = this.stack[this.stack.length - 1]\n    assert(node, 'expected node on stack')\n    assert(node.type === 'link', 'expected link on stack')\n\n    node.url = 'mailto:' + this.sliceSerialize(token)\n  }\n\n  //\n  // Creaters.\n  //\n\n  /** @returns {Blockquote} */\n  function blockQuote() {\n    return {type: 'blockquote', children: []}\n  }\n\n  /** @returns {Code} */\n  function codeFlow() {\n    return {type: 'code', lang: null, meta: null, value: ''}\n  }\n\n  /** @returns {InlineCode} */\n  function codeText() {\n    return {type: 'inlineCode', value: ''}\n  }\n\n  /** @returns {Definition} */\n  function definition() {\n    return {\n      type: 'definition',\n      identifier: '',\n      label: null,\n      title: null,\n      url: ''\n    }\n  }\n\n  /** @returns {Emphasis} */\n  function emphasis() {\n    return {type: 'emphasis', children: []}\n  }\n\n  /** @returns {Heading} */\n  function heading() {\n    return {\n      type: 'heading',\n      // @ts-expect-error `depth` will be set later.\n      depth: 0,\n      children: []\n    }\n  }\n\n  /** @returns {Break} */\n  function hardBreak() {\n    return {type: 'break'}\n  }\n\n  /** @returns {Html} */\n  function html() {\n    return {type: 'html', value: ''}\n  }\n\n  /** @returns {Image} */\n  function image() {\n    return {type: 'image', title: null, url: '', alt: null}\n  }\n\n  /** @returns {Link} */\n  function link() {\n    return {type: 'link', title: null, url: '', children: []}\n  }\n\n  /**\n   * @param {Token} token\n   * @returns {List}\n   */\n  function list(token) {\n    return {\n      type: 'list',\n      ordered: token.type === 'listOrdered',\n      start: null,\n      spread: token._spread,\n      children: []\n    }\n  }\n\n  /**\n   * @param {Token} token\n   * @returns {ListItem}\n   */\n  function listItem(token) {\n    return {\n      type: 'listItem',\n      spread: token._spread,\n      checked: null,\n      children: []\n    }\n  }\n\n  /** @returns {Paragraph} */\n  function paragraph() {\n    return {type: 'paragraph', children: []}\n  }\n\n  /** @returns {Strong} */\n  function strong() {\n    return {type: 'strong', children: []}\n  }\n\n  /** @returns {Text} */\n  function text() {\n    return {type: 'text', value: ''}\n  }\n\n  /** @returns {ThematicBreak} */\n  function thematicBreak() {\n    return {type: 'thematicBreak'}\n  }\n}\n\n/**\n * Copy a point-like value.\n *\n * @param {Point} d\n *   Point-like value.\n * @returns {Point}\n *   unist point.\n */\nfunction point(d) {\n  return {line: d.line, column: d.column, offset: d.offset}\n}\n\n/**\n * @param {Config} combined\n * @param {Array<Array<Extension> | Extension>} extensions\n * @returns {undefined}\n */\nfunction configure(combined, extensions) {\n  let index = -1\n\n  while (++index < extensions.length) {\n    const value = extensions[index]\n\n    if (Array.isArray(value)) {\n      configure(combined, value)\n    } else {\n      extension(combined, value)\n    }\n  }\n}\n\n/**\n * @param {Config} combined\n * @param {Extension} extension\n * @returns {undefined}\n */\nfunction extension(combined, extension) {\n  /** @type {keyof Extension} */\n  let key\n\n  for (key in extension) {\n    if (own.call(extension, key)) {\n      switch (key) {\n        case 'canContainEols': {\n          const right = extension[key]\n          if (right) {\n            combined[key].push(...right)\n          }\n\n          break\n        }\n\n        case 'transforms': {\n          const right = extension[key]\n          if (right) {\n            combined[key].push(...right)\n          }\n\n          break\n        }\n\n        case 'enter':\n        case 'exit': {\n          const right = extension[key]\n          if (right) {\n            Object.assign(combined[key], right)\n          }\n\n          break\n        }\n        // No default\n      }\n    }\n  }\n}\n\n/** @type {OnEnterError} */\nfunction defaultOnError(left, right) {\n  if (left) {\n    throw new Error(\n      'Cannot close `' +\n        left.type +\n        '` (' +\n        stringifyPosition({start: left.start, end: left.end}) +\n        '): a different token (`' +\n        right.type +\n        '`, ' +\n        stringifyPosition({start: right.start, end: right.end}) +\n        ') is open'\n    )\n  } else {\n    throw new Error(\n      'Cannot close document, a token (`' +\n        right.type +\n        '`, ' +\n        stringifyPosition({start: right.start, end: right.end}) +\n        ') is still open'\n    )\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAuCC;;;;AAED;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;;;;;;;;;;AAEA,MAAM,MAAM,CAAC,EAAE,cAAc;AAyBtB,SAAS,aAAa,KAAK,EAAE,QAAQ,EAAE,OAAO;IACnD,IAAI,OAAO,aAAa,UAAU;QAChC,UAAU;QACV,WAAW;IACb;IAEA,OAAO,SAAS,SACd,IAAA,gQAAW,EACT,IAAA,oPAAK,EAAC,SACH,QAAQ,GACR,KAAK,CAAC,IAAA,8PAAU,IAAG,OAAO,UAAU;AAG7C;AAEA;;;;CAIC,GACD,SAAS,SAAS,OAAO;IACvB,mBAAmB,GACnB,MAAM,SAAS;QACb,YAAY,EAAE;QACd,gBAAgB;YAAC;YAAY;YAAY;YAAW;YAAa;SAAS;QAC1E,OAAO;YACL,UAAU,OAAO;YACjB,kBAAkB;YAClB,eAAe;YACf,YAAY,OAAO;YACnB,YAAY,OAAO;YACnB,iBAAiB;YACjB,oBAAoB;YACpB,YAAY,OAAO;YACnB,qBAAqB;YACrB,qBAAqB;YACrB,cAAc,OAAO,UAAU;YAC/B,UAAU,OAAO,UAAU;YAC3B,cAAc;YACd,MAAM;YACN,eAAe;YACf,YAAY,OAAO;YACnB,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU,OAAO;YACjB,iBAAiB,OAAO;YACxB,mBAAmB,OAAO;YAC1B,UAAU,OAAO,MAAM;YACvB,cAAc;YACd,UAAU,OAAO,MAAM;YACvB,cAAc;YACd,OAAO,OAAO;YACd,OAAO;YACP,MAAM,OAAO;YACb,UAAU,OAAO;YACjB,eAAe;YACf,aAAa,OAAO,MAAM;YAC1B,eAAe,OAAO;YACtB,WAAW,OAAO;YAClB,WAAW;YACX,iBAAiB;YACjB,2BAA2B;YAC3B,qBAAqB;YACrB,eAAe,OAAO;YACtB,QAAQ,OAAO;YACf,eAAe,OAAO;QACxB;QACA,MAAM;YACJ,YAAY;YACZ,oBAAoB;YACpB,UAAU;YACV,eAAe;YACf,kBAAkB;YAClB,YAAY;YACZ,sBAAsB;YACtB,qCAAqC;YACrC,iCAAiC;YACjC,yBAAyB;YACzB,oBAAoB;YACpB,YAAY,OAAO;YACnB,iBAAiB;YACjB,qBAAqB;YACrB,qBAAqB;YACrB,eAAe;YACf,cAAc,OAAO;YACrB,UAAU,OAAO;YACjB,cAAc;YACd,MAAM;YACN,YAAY;YACZ,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU;YACV,iBAAiB,OAAO;YACxB,mBAAmB,OAAO;YAC1B,UAAU,OAAO;YACjB,cAAc;YACd,UAAU,OAAO;YACjB,cAAc;YACd,OAAO,OAAO;YACd,OAAO;YACP,WAAW;YACX,YAAY;YACZ,MAAM,OAAO;YACb,UAAU;YACV,aAAa;YACb,eAAe;YACf,WAAW;YACX,iBAAiB;YACjB,2BAA2B;YAC3B,qBAAqB;YACrB,UAAU;YACV,eAAe,OAAO;YACtB,2BAA2B;YAC3B,mBAAmB;YACnB,QAAQ;YACR,eAAe;QACjB;IACF;IAEA,UAAU,QAAQ,CAAC,WAAW,CAAC,CAAC,EAAE,eAAe,IAAI,EAAE;IAEvD,wBAAwB,GACxB,MAAM,OAAO,CAAC;IAEd,OAAO;;;IAEP;;;;;;;GAOC,GACD,SAAS,QAAQ,MAAM;QACrB,iBAAiB,GACjB,IAAI,OAAO;YAAC,MAAM;YAAQ,UAAU,EAAE;QAAA;QACtC,mDAAmD,GACnD,MAAM,UAAU;YACd,OAAO;gBAAC;aAAK;YACb,YAAY,EAAE;YACd;YACA;YACA;YACA;YACA;YACA;QACF;QACA,0BAA0B,GAC1B,MAAM,YAAY,EAAE;QACpB,IAAI,QAAQ,CAAC;QAEb,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,qEAAqE;YACrE,wCAAwC;YACxC,IACE,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,WAAW,IAC3C,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,aAAa,EAC7C;gBACA,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,SAAS;oBAChC,UAAU,IAAI,CAAC;gBACjB,OAAO;oBACL,MAAM,OAAO,UAAU,GAAG;oBAC1B,IAAA,wLAAM,EAAC,OAAO,SAAS,UAAU;oBACjC,QAAQ,YAAY,QAAQ,MAAM;gBACpC;YACF;QACF;QAEA,QAAQ,CAAC;QAET,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,MAAM,UAAU,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC;YAExC,IAAI,IAAI,IAAI,CAAC,SAAS,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,GAAG;gBAC5C,OAAO,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CACjC,OAAO,MAAM,CACX;oBAAC,gBAAgB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,cAAc;gBAAA,GAChD,UAEF,MAAM,CAAC,MAAM,CAAC,EAAE;YAEpB;QACF;QAEA,kCAAkC;QAClC,IAAI,QAAQ,UAAU,CAAC,MAAM,GAAG,GAAG;YACjC,MAAM,OAAO,QAAQ,UAAU,CAAC,QAAQ,UAAU,CAAC,MAAM,GAAG,EAAE;YAC9D,MAAM,UAAU,IAAI,CAAC,EAAE,IAAI;YAC3B,QAAQ,IAAI,CAAC,SAAS,WAAW,IAAI,CAAC,EAAE;QAC1C;QAEA,8BAA8B;QAC9B,KAAK,QAAQ,GAAG;YACd,OAAO,MACL,OAAO,MAAM,GAAG,IAAI,MAAM,CAAC,EAAE,CAAC,EAAE,CAAC,KAAK,GAAG;gBAAC,MAAM;gBAAG,QAAQ;gBAAG,QAAQ;YAAC;YAEzE,KAAK,MACH,OAAO,MAAM,GAAG,IACZ,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE,CAAC,EAAE,CAAC,GAAG,GAChC;gBAAC,MAAM;gBAAG,QAAQ;gBAAG,QAAQ;YAAC;QAEtC;QAEA,mBAAmB;QACnB,QAAQ,CAAC;QACT,MAAO,EAAE,QAAQ,OAAO,UAAU,CAAC,MAAM,CAAE;YACzC,OAAO,OAAO,UAAU,CAAC,MAAM,CAAC,SAAS;QAC3C;QAEA,OAAO;IACT;IAEA;;;;;GAKC,GACD,SAAS,YAAY,MAAM,EAAE,KAAK,EAAE,MAAM;QACxC,IAAI,QAAQ,QAAQ;QACpB,IAAI,mBAAmB,CAAC;QACxB,IAAI,aAAa;QACjB,8BAA8B,GAC9B,IAAI;QACJ,+BAA+B,GAC/B,IAAI;QACJ,+BAA+B,GAC/B,IAAI;QACJ,gCAAgC,GAChC,IAAI;QAEJ,MAAO,EAAE,SAAS,OAAQ;YACxB,MAAM,QAAQ,MAAM,CAAC,MAAM;YAE3B,OAAQ,KAAK,CAAC,EAAE,CAAC,IAAI;gBACnB,KAAK,0MAAK,CAAC,aAAa;gBACxB,KAAK,0MAAK,CAAC,WAAW;gBACtB,KAAK,0MAAK,CAAC,UAAU;oBAAE;wBACrB,IAAI,KAAK,CAAC,EAAE,KAAK,SAAS;4BACxB;wBACF,OAAO;4BACL;wBACF;wBAEA,WAAW;wBAEX;oBACF;gBAEA,KAAK,0MAAK,CAAC,eAAe;oBAAE;wBAC1B,IAAI,KAAK,CAAC,EAAE,KAAK,SAAS;4BACxB,IACE,YACA,CAAC,YACD,CAAC,oBACD,CAAC,qBACD;gCACA,sBAAsB;4BACxB;4BAEA,WAAW;wBACb;wBAEA;oBACF;gBAEA,KAAK,0MAAK,CAAC,UAAU;gBACrB,KAAK,0MAAK,CAAC,aAAa;gBACxB,KAAK,0MAAK,CAAC,cAAc;gBACzB,KAAK,0MAAK,CAAC,cAAc;gBACzB,KAAK,0MAAK,CAAC,wBAAwB;oBAAE;wBAGnC;oBACF;gBAEA;oBAAS;wBACP,WAAW;oBACb;YACF;YAEA,IACE,AAAC,CAAC,oBACA,KAAK,CAAC,EAAE,KAAK,WACb,KAAK,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,cAAc,IACvC,qBAAqB,CAAC,KACrB,KAAK,CAAC,EAAE,KAAK,UACb,CAAC,KAAK,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,aAAa,IACpC,KAAK,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,WAAW,GACvC;gBACA,IAAI,UAAU;oBACZ,IAAI,YAAY;oBAChB,YAAY;oBAEZ,MAAO,YAAa;wBAClB,MAAM,YAAY,MAAM,CAAC,UAAU;wBAEnC,IACE,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,UAAU,IACtC,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,eAAe,EAC3C;4BACA,IAAI,SAAS,CAAC,EAAE,KAAK,QAAQ;4BAE7B,IAAI,WAAW;gCACb,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,IAAI,GAAG,0MAAK,CAAC,eAAe;gCACjD,aAAa;4BACf;4BAEA,SAAS,CAAC,EAAE,CAAC,IAAI,GAAG,0MAAK,CAAC,UAAU;4BACpC,YAAY;wBACd,OAAO,IACL,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,UAAU,IACtC,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,gBAAgB,IAC5C,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,0BAA0B,IACtD,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,gBAAgB,IAC5C,SAAS,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,cAAc,EAC1C;wBACA,QAAQ;wBACV,OAAO;4BACL;wBACF;oBACF;oBAEA,IACE,uBACA,CAAC,CAAC,aAAa,sBAAsB,SAAS,GAC9C;wBACA,SAAS,OAAO,GAAG;oBACrB;oBAEA,gBAAgB;oBAChB,SAAS,GAAG,GAAG,OAAO,MAAM,CAC1B,CAAC,GACD,YAAY,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,KAAK,GAAG,KAAK,CAAC,EAAE,CAAC,GAAG;oBAGvD,OAAO,MAAM,CAAC,aAAa,OAAO,GAAG;wBAAC;wBAAQ;wBAAU,KAAK,CAAC,EAAE;qBAAC;oBACjE;oBACA;gBACF;gBAEA,0BAA0B;gBAC1B,IAAI,KAAK,CAAC,EAAE,CAAC,IAAI,KAAK,0MAAK,CAAC,cAAc,EAAE;oBAC1C,kBAAkB,GAClB,MAAM,OAAO;wBACX,MAAM;wBACN,SAAS;wBACT,OAAO,OAAO,MAAM,CAAC,CAAC,GAAG,KAAK,CAAC,EAAE,CAAC,KAAK;wBACvC,iDAAiD;wBACjD,KAAK;oBACP;oBACA,WAAW;oBACX,OAAO,MAAM,CAAC,OAAO,GAAG;wBAAC;wBAAS;wBAAM,KAAK,CAAC,EAAE;qBAAC;oBACjD;oBACA;oBACA,sBAAsB;oBACtB,WAAW;gBACb;YACF;QACF;QAEA,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,OAAO,GAAG;QAC3B,OAAO;IACT;IAEA;;;;;;;;;GASC,GACD,SAAS,OAAO,MAAM,EAAE,GAAG;QACzB,OAAO;;;QAEP;;;;KAIC,GACD,SAAS,KAAK,KAAK;YACjB,MAAM,IAAI,CAAC,IAAI,EAAE,OAAO,QAAQ;YAChC,IAAI,KAAK,IAAI,IAAI,CAAC,IAAI,EAAE;QAC1B;IACF;IAEA;;GAEC,GACD,SAAS;QACP,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;YAAC,MAAM;YAAY,UAAU,EAAE;QAAA;IACjD;IAEA;;GAEC,GACD,SAAS,MAAM,IAAI,EAAE,KAAK,EAAE,YAAY;QACtC,MAAM,SAAS,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAChD,IAAA,wLAAM,EAAC,QAAQ;QACf,IAAA,wLAAM,EAAC,cAAc,QAAQ;QAC7B,yBAAyB,GACzB,MAAM,WAAW,OAAO,QAAQ;QAChC,SAAS,IAAI,CAAC;QACd,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;QAChB,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC;YAAC;YAAO,gBAAgB;SAAU;QACvD,KAAK,QAAQ,GAAG;YACd,OAAO,MAAM,MAAM,KAAK;YACxB,iDAAiD;YACjD,KAAK;QACP;IACF;IAEA;;;;;;;GAOC,GACD,SAAS,OAAO,GAAG;QACjB,OAAO;;;QAEP;;;;KAIC,GACD,SAAS,MAAM,KAAK;YAClB,IAAI,KAAK,IAAI,IAAI,CAAC,IAAI,EAAE;YACxB,KAAK,IAAI,CAAC,IAAI,EAAE;QAClB;IACF;IAEA;;GAEC,GACD,SAAS,KAAK,KAAK,EAAE,WAAW;QAC9B,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,GAAG;QAC3B,IAAA,wLAAM,EAAC,MAAM;QACb,MAAM,OAAO,IAAI,CAAC,UAAU,CAAC,GAAG;QAEhC,IAAI,CAAC,MAAM;YACT,MAAM,IAAI,MACR,mBACE,MAAM,IAAI,GACV,QACA,IAAA,sRAAiB,EAAC;gBAAC,OAAO,MAAM,KAAK;gBAAE,KAAK,MAAM,GAAG;YAAA,KACrD;QAEN,OAAO,IAAI,IAAI,CAAC,EAAE,CAAC,IAAI,KAAK,MAAM,IAAI,EAAE;YACtC,IAAI,aAAa;gBACf,YAAY,IAAI,CAAC,IAAI,EAAE,OAAO,IAAI,CAAC,EAAE;YACvC,OAAO;gBACL,MAAM,UAAU,IAAI,CAAC,EAAE,IAAI;gBAC3B,QAAQ,IAAI,CAAC,IAAI,EAAE,OAAO,IAAI,CAAC,EAAE;YACnC;QACF;QAEA,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,YAAY;QACjC,IAAA,wLAAM,EAAC,KAAK,QAAQ,EAAE;QACtB,KAAK,QAAQ,CAAC,GAAG,GAAG,MAAM,MAAM,GAAG;IACrC;IAEA;;GAEC,GACD,SAAS;QACP,OAAO,IAAA,+MAAQ,EAAC,IAAI,CAAC,KAAK,CAAC,GAAG;IAChC;IAEA,EAAE;IACF,YAAY;IACZ,EAAE;IAEF;;;GAGC,GACD,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,2BAA2B,GAAG;IAC1C;IAEA;;;GAGC,GACD,SAAS,qBAAqB,KAAK;QACjC,IAAI,IAAI,CAAC,IAAI,CAAC,2BAA2B,EAAE;YACzC,MAAM,WAAW,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;YAClD,IAAA,wLAAM,EAAC,UAAU;YACjB,IAAA,wLAAM,EAAC,SAAS,IAAI,KAAK,QAAQ;YACjC,SAAS,KAAK,GAAG,OAAO,QAAQ,CAC9B,IAAI,CAAC,cAAc,CAAC,QACpB,kNAAS,CAAC,kBAAkB;YAE9B,IAAI,CAAC,IAAI,CAAC,2BAA2B,GAAG;QAC1C;IACF;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAC7B,KAAK,IAAI,GAAG;IACd;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAC7B,KAAK,IAAI,GAAG;IACd;IAEA;;;GAGC,GACD,SAAS;QACP,qCAAqC;QACrC,IAAI,IAAI,CAAC,IAAI,CAAC,cAAc,EAAE;QAC9B,IAAI,CAAC,MAAM;QACX,IAAI,CAAC,IAAI,CAAC,cAAc,GAAG;IAC7B;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,KAAK,GAAG,KAAK,OAAO,CAAC,4BAA4B;QACtD,IAAI,CAAC,IAAI,CAAC,cAAc,GAAG;IAC7B;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,KAAK,GAAG,KAAK,OAAO,CAAC,gBAAgB;IAC5C;IAEA;;;GAGC,GACD,SAAS,4BAA4B,KAAK;QACxC,MAAM,QAAQ,IAAI,CAAC,MAAM;QACzB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,cAAc;QAEnC,KAAK,KAAK,GAAG;QACb,KAAK,UAAU,GAAG,IAAA,yOAAmB,EACnC,IAAI,CAAC,cAAc,CAAC,QACpB,WAAW;IACf;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,cAAc;QAEnC,KAAK,KAAK,GAAG;IACf;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,cAAc;QAEnC,KAAK,GAAG,GAAG;IACb;IAEA;;;GAGC,GACD,SAAS,yBAAyB,KAAK;QACrC,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,WAAW;QAEhC,IAAI,CAAC,KAAK,KAAK,EAAE;YACf,MAAM,QAAQ,IAAI,CAAC,cAAc,CAAC,OAAO,MAAM;YAE/C,IAAA,wLAAM,EACJ,UAAU,KACR,UAAU,KACV,UAAU,KACV,UAAU,KACV,UAAU,KACV,UAAU,GACZ;YAGF,KAAK,KAAK,GAAG;QACf;IACF;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,4BAA4B,GAAG;IAC3C;IAEA;;;GAGC,GACD,SAAS,gCAAgC,KAAK;QAC5C,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,WAAW;QAEhC,KAAK,KAAK,GACR,IAAI,CAAC,cAAc,CAAC,OAAO,WAAW,CAAC,OAAO,0MAAK,CAAC,QAAQ,GAAG,IAAI;IACvE;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,4BAA4B,GAAG;IAC3C;IAEA;;;GAGC,GAED,SAAS,YAAY,KAAK;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,cAAc,MAAM;QAC3B,yBAAyB,GACzB,MAAM,WAAW,KAAK,QAAQ;QAE9B,IAAI,OAAO,QAAQ,CAAC,SAAS,MAAM,GAAG,EAAE;QAExC,IAAI,CAAC,QAAQ,KAAK,IAAI,KAAK,QAAQ;YACjC,uBAAuB;YACvB,OAAO;YACP,KAAK,QAAQ,GAAG;gBACd,OAAO,MAAM,MAAM,KAAK;gBACxB,2CAA2C;gBAC3C,KAAK;YACP;YACA,SAAS,IAAI,CAAC;QAChB;QAEA,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;IAClB;IAEA;;;GAGC,GAED,SAAS,WAAW,KAAK;QACvB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,GAAG;QAC3B,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,WAAW,MAAM;QACxB,IAAA,wLAAM,EAAC,KAAK,QAAQ,EAAE;QACtB,KAAK,KAAK,IAAI,IAAI,CAAC,cAAc,CAAC;QAClC,KAAK,QAAQ,CAAC,GAAG,GAAG,MAAM,MAAM,GAAG;IACrC;IAEA;;;GAGC,GAED,SAAS,iBAAiB,KAAK;QAC7B,MAAM,UAAU,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QACjD,IAAA,wLAAM,EAAC,SAAS;QAEhB,8DAA8D;QAC9D,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE;YACzB,IAAA,wLAAM,EAAC,cAAc,SAAS;YAC9B,MAAM,OAAO,QAAQ,QAAQ,CAAC,QAAQ,QAAQ,CAAC,MAAM,GAAG,EAAE;YAC1D,IAAA,wLAAM,EAAC,KAAK,QAAQ,EAAE;YACtB,KAAK,QAAQ,CAAC,GAAG,GAAG,MAAM,MAAM,GAAG;YACnC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG;YACxB;QACF;QAEA,IACE,CAAC,IAAI,CAAC,IAAI,CAAC,4BAA4B,IACvC,OAAO,cAAc,CAAC,QAAQ,CAAC,QAAQ,IAAI,GAC3C;YACA,YAAY,IAAI,CAAC,IAAI,EAAE;YACvB,WAAW,IAAI,CAAC,IAAI,EAAE;QACxB;IACF;IAEA;;;GAGC,GAED,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG;IAC1B;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,KAAK,GAAG;IACf;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,KAAK,GAAG;IACf;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,cAAc;QAEnC,KAAK,KAAK,GAAG;IACf;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,0EAA0E;QAC1E,iCAAiC;QAEjC,gBAAgB;QAChB,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE;YACzB,0BAA0B,GAC1B,MAAM,gBAAgB,IAAI,CAAC,IAAI,CAAC,aAAa,IAAI;YAEjD,KAAK,IAAI,IAAI;YACb,4BAA4B;YAC5B,KAAK,aAAa,GAAG;YACrB,4BAA4B;YAC5B,OAAO,KAAK,GAAG;YACf,OAAO,KAAK,KAAK;QACnB,OAAO;YACL,4BAA4B;YAC5B,OAAO,KAAK,UAAU;YACtB,4BAA4B;YAC5B,OAAO,KAAK,KAAK;QACnB;QAEA,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG;IAC5B;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,SAAS;QAE9B,0EAA0E;QAC1E,iCAAiC;QAEjC,gBAAgB;QAChB,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE;YACzB,0BAA0B,GAC1B,MAAM,gBAAgB,IAAI,CAAC,IAAI,CAAC,aAAa,IAAI;YAEjD,KAAK,IAAI,IAAI;YACb,4BAA4B;YAC5B,KAAK,aAAa,GAAG;YACrB,4BAA4B;YAC5B,OAAO,KAAK,GAAG;YACf,OAAO,KAAK,KAAK;QACnB,OAAO;YACL,4BAA4B;YAC5B,OAAO,KAAK,UAAU;YACtB,4BAA4B;YAC5B,OAAO,KAAK,KAAK;QACnB;QAEA,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG;IAC5B;IAEA;;;GAGC,GAED,SAAS,gBAAgB,KAAK;QAC5B,MAAM,SAAS,IAAI,CAAC,cAAc,CAAC;QACnC,MAAM,WAAW,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAClD,IAAA,wLAAM,EAAC,UAAU;QACjB,IAAA,wLAAM,EACJ,SAAS,IAAI,KAAK,WAAW,SAAS,IAAI,KAAK,QAC/C;QAGF,2EAA2E;QAC3E,SAAS;QACT,SAAS,KAAK,GAAG,IAAA,2NAAY,EAAC;QAC9B,mCAAmC;QACnC,SAAS,UAAU,GAAG,IAAA,yOAAmB,EAAC,QAAQ,WAAW;IAC/D;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,WAAW,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAClD,IAAA,wLAAM,EAAC,UAAU;QACjB,IAAA,wLAAM,EAAC,SAAS,IAAI,KAAK,YAAY;QACrC,MAAM,QAAQ,IAAI,CAAC,MAAM;QACzB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EACJ,KAAK,IAAI,KAAK,WAAW,KAAK,IAAI,KAAK,QACvC;QAGF,sBAAsB;QACtB,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG;QAExB,IAAI,KAAK,IAAI,KAAK,QAAQ;YACxB,mCAAmC,GACnC,MAAM,WAAW,SAAS,QAAQ;YAElC,KAAK,QAAQ,GAAG;QAClB,OAAO;YACL,KAAK,GAAG,GAAG;QACb;IACF;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EACJ,KAAK,IAAI,KAAK,WAAW,KAAK,IAAI,KAAK,QACvC;QAEF,KAAK,GAAG,GAAG;IACb;IAEA;;;GAGC,GAED,SAAS;QACP,MAAM,OAAO,IAAI,CAAC,MAAM;QACxB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EACJ,KAAK,IAAI,KAAK,WAAW,KAAK,IAAI,KAAK,QACvC;QAEF,KAAK,KAAK,GAAG;IACf;IAEA;;;GAGC,GAED,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG;IAC1B;IAEA;;;GAGC,GAED,SAAS;QACP,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG;IAC5B;IAEA;;;GAGC,GAED,SAAS,sBAAsB,KAAK;QAClC,MAAM,QAAQ,IAAI,CAAC,MAAM;QACzB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EACJ,KAAK,IAAI,KAAK,WAAW,KAAK,IAAI,KAAK,QACvC;QAGF,2EAA2E;QAC3E,SAAS;QACT,KAAK,KAAK,GAAG;QACb,mCAAmC;QACnC,KAAK,UAAU,GAAG,IAAA,yOAAmB,EACnC,IAAI,CAAC,cAAc,CAAC,QACpB,WAAW;QACb,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG;IAC5B;IAEA;;;GAGC,GAED,SAAS,+BAA+B,KAAK;QAC3C,IAAA,wLAAM,EACJ,MAAM,IAAI,KAAK,qCACb,MAAM,IAAI,KAAK;QAEnB,IAAI,CAAC,IAAI,CAAC,sBAAsB,GAAG,MAAM,IAAI;IAC/C;IAEA;;;GAGC,GACD,SAAS,8BAA8B,KAAK;QAC1C,MAAM,OAAO,IAAI,CAAC,cAAc,CAAC;QACjC,MAAM,OAAO,IAAI,CAAC,IAAI,CAAC,sBAAsB;QAC7C,mBAAmB,GACnB,IAAI;QAEJ,IAAI,MAAM;YACR,QAAQ,IAAA,8TAA+B,EACrC,MACA,SAAS,0MAAK,CAAC,+BAA+B,GAC1C,kNAAS,CAAC,kBAAkB,GAC5B,kNAAS,CAAC,sBAAsB;YAEtC,IAAI,CAAC,IAAI,CAAC,sBAAsB,GAAG;QACrC,OAAO;YACL,MAAM,SAAS,IAAA,yOAA6B,EAAC;YAC7C,IAAA,wLAAM,EAAC,WAAW,OAAO;YACzB,QAAQ;QACV;QAEA,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,WAAW,MAAM;QACxB,KAAK,KAAK,IAAI;IAChB;IAEA;;;GAGC,GACD,SAAS,yBAAyB,KAAK;QACrC,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,GAAG;QAC3B,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,QAAQ,EAAE;QACtB,KAAK,QAAQ,CAAC,GAAG,GAAG,MAAM,MAAM,GAAG;IACrC;IAEA;;;GAGC,GACD,SAAS,uBAAuB,KAAK;QACnC,WAAW,IAAI,CAAC,IAAI,EAAE;QACtB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,GAAG,GAAG,IAAI,CAAC,cAAc,CAAC;IACjC;IAEA;;;GAGC,GACD,SAAS,oBAAoB,KAAK;QAChC,WAAW,IAAI,CAAC,IAAI,EAAE;QACtB,MAAM,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,EAAE;QAC9C,IAAA,wLAAM,EAAC,MAAM;QACb,IAAA,wLAAM,EAAC,KAAK,IAAI,KAAK,QAAQ;QAE7B,KAAK,GAAG,GAAG,YAAY,IAAI,CAAC,cAAc,CAAC;IAC7C;IAEA,EAAE;IACF,YAAY;IACZ,EAAE;IAEF,0BAA0B,GAC1B,SAAS;QACP,OAAO;YAAC,MAAM;YAAc,UAAU,EAAE;QAAA;IAC1C;IAEA,oBAAoB,GACpB,SAAS;QACP,OAAO;YAAC,MAAM;YAAQ,MAAM;YAAM,MAAM;YAAM,OAAO;QAAE;IACzD;IAEA,0BAA0B,GAC1B,SAAS;QACP,OAAO;YAAC,MAAM;YAAc,OAAO;QAAE;IACvC;IAEA,0BAA0B,GAC1B,SAAS;QACP,OAAO;YACL,MAAM;YACN,YAAY;YACZ,OAAO;YACP,OAAO;YACP,KAAK;QACP;IACF;IAEA,wBAAwB,GACxB,SAAS;QACP,OAAO;YAAC,MAAM;YAAY,UAAU,EAAE;QAAA;IACxC;IAEA,uBAAuB,GACvB,SAAS;QACP,OAAO;YACL,MAAM;YACN,8CAA8C;YAC9C,OAAO;YACP,UAAU,EAAE;QACd;IACF;IAEA,qBAAqB,GACrB,SAAS;QACP,OAAO;YAAC,MAAM;QAAO;IACvB;IAEA,oBAAoB,GACpB,SAAS;QACP,OAAO;YAAC,MAAM;YAAQ,OAAO;QAAE;IACjC;IAEA,qBAAqB,GACrB,SAAS;QACP,OAAO;YAAC,MAAM;YAAS,OAAO;YAAM,KAAK;YAAI,KAAK;QAAI;IACxD;IAEA,oBAAoB,GACpB,SAAS;QACP,OAAO;YAAC,MAAM;YAAQ,OAAO;YAAM,KAAK;YAAI,UAAU,EAAE;QAAA;IAC1D;IAEA;;;GAGC,GACD,SAAS,KAAK,KAAK;QACjB,OAAO;YACL,MAAM;YACN,SAAS,MAAM,IAAI,KAAK;YACxB,OAAO;YACP,QAAQ,MAAM,OAAO;YACrB,UAAU,EAAE;QACd;IACF;IAEA;;;GAGC,GACD,SAAS,SAAS,KAAK;QACrB,OAAO;YACL,MAAM;YACN,QAAQ,MAAM,OAAO;YACrB,SAAS;YACT,UAAU,EAAE;QACd;IACF;IAEA,yBAAyB,GACzB,SAAS;QACP,OAAO;YAAC,MAAM;YAAa,UAAU,EAAE;QAAA;IACzC;IAEA,sBAAsB,GACtB,SAAS;QACP,OAAO;YAAC,MAAM;YAAU,UAAU,EAAE;QAAA;IACtC;IAEA,oBAAoB,GACpB,SAAS;QACP,OAAO;YAAC,MAAM;YAAQ,OAAO;QAAE;IACjC;IAEA,6BAA6B,GAC7B,SAAS;QACP,OAAO;YAAC,MAAM;QAAe;IAC/B;AACF;AAEA;;;;;;;CAOC,GACD,SAAS,MAAM,CAAC;IACd,OAAO;QAAC,MAAM,EAAE,IAAI;QAAE,QAAQ,EAAE,MAAM;QAAE,QAAQ,EAAE,MAAM;IAAA;AAC1D;AAEA;;;;CAIC,GACD,SAAS,UAAU,QAAQ,EAAE,UAAU;IACrC,IAAI,QAAQ,CAAC;IAEb,MAAO,EAAE,QAAQ,WAAW,MAAM,CAAE;QAClC,MAAM,QAAQ,UAAU,CAAC,MAAM;QAE/B,IAAI,MAAM,OAAO,CAAC,QAAQ;YACxB,UAAU,UAAU;QACtB,OAAO;YACL,UAAU,UAAU;QACtB;IACF;AACF;AAEA;;;;CAIC,GACD,SAAS,UAAU,QAAQ,EAAE,SAAS;IACpC,4BAA4B,GAC5B,IAAI;IAEJ,IAAK,OAAO,UAAW;QACrB,IAAI,IAAI,IAAI,CAAC,WAAW,MAAM;YAC5B,OAAQ;gBACN,KAAK;oBAAkB;wBACrB,MAAM,QAAQ,SAAS,CAAC,IAAI;wBAC5B,IAAI,OAAO;4BACT,QAAQ,CAAC,IAAI,CAAC,IAAI,IAAI;wBACxB;wBAEA;oBACF;gBAEA,KAAK;oBAAc;wBACjB,MAAM,QAAQ,SAAS,CAAC,IAAI;wBAC5B,IAAI,OAAO;4BACT,QAAQ,CAAC,IAAI,CAAC,IAAI,IAAI;wBACxB;wBAEA;oBACF;gBAEA,KAAK;gBACL,KAAK;oBAAQ;wBACX,MAAM,QAAQ,SAAS,CAAC,IAAI;wBAC5B,IAAI,OAAO;4BACT,OAAO,MAAM,CAAC,QAAQ,CAAC,IAAI,EAAE;wBAC/B;wBAEA;oBACF;YAEF;QACF;IACF;AACF;AAEA,yBAAyB,GACzB,SAAS,eAAe,IAAI,EAAE,KAAK;IACjC,IAAI,MAAM;QACR,MAAM,IAAI,MACR,mBACE,KAAK,IAAI,GACT,QACA,IAAA,sRAAiB,EAAC;YAAC,OAAO,KAAK,KAAK;YAAE,KAAK,KAAK,GAAG;QAAA,KACnD,4BACA,MAAM,IAAI,GACV,QACA,IAAA,sRAAiB,EAAC;YAAC,OAAO,MAAM,KAAK;YAAE,KAAK,MAAM,GAAG;QAAA,KACrD;IAEN,OAAO;QACL,MAAM,IAAI,MACR,sCACE,MAAM,IAAI,GACV,QACA,IAAA,sRAAiB,EAAC;YAAC,OAAO,MAAM,KAAK;YAAE,KAAK,MAAM,GAAG;QAAA,KACrD;IAEN;AACF","ignoreList":[0],"debugId":null}}]
}